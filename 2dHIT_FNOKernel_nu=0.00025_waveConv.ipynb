{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time \n",
    "import scipy\n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('./utils/tecplot.mplstyle')\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# import neuralop \n",
    "# from utilities import *\n",
    "from utils.neuraloperator import * \n",
    "\n",
    "from pathlib import Path\n",
    "from torch import Tensor\n",
    "from typing import Any, List, Tuple, Mapping, Optional, Iterable, Union, Dict, Literal\n",
    "\n",
    "## libraries for CFD\n",
    "# import cupy as cp\n",
    "import h5py \n",
    "import yaml\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'name': '2dHIT_FNOKernel_nu=0.000225_T=0.25_fDNS=64', \n",
    "    'model': {\n",
    "        'name': '2dHIT_FNOKernel_nu=0.000225_T=0.25_fDNS=64',\n",
    "        'params': {\n",
    "            'n_modes': (32, 32), \n",
    "            'in_channels': 1, \n",
    "            'out_channels': 1, \n",
    "            'hidden_channels': 64, \n",
    "            'lifting_channel_ratio': 2, \n",
    "            'projection_channel_ratio': 8, \n",
    "\n",
    "            # 'factorization':'tucker',\n",
    "            # 'implementation':'factorized',\n",
    "            # 'rank': 2, \n",
    "            'n_layers': 4,\n",
    "            'norm': 'instance_norm', # (None, 'instance_norm', 'group_norm', 'ada_in'); 'ada_in'은 에러남 \n",
    "            # 'fno_skip': 'linear', # ('linear', 'soft-gating', 'identity')\n",
    "            # 'channel_mlp_skip': 'linear', # ('soft-gating', 'linear', 'identity')\n",
    "            'positional_embedding': None, # (None, 'grid', GridEmbedding2D, GridEmbeddingnD)\n",
    "            # 'implementation': 'factorized', # ('factorized', 'reconstructed')\n",
    "            # 'fft_norm': 'forward', # ('forward', 'ortho', 'backward')\n",
    "            # 'fno_block_precision': 'full', # ('full', 'mixed', 'half')\n",
    "            'use_channel_mlp': False, \n",
    "\n",
    "            # 'SpectralConv_initializer': 'zeros', # ('normal', 'uniform', 'constant', 'ones', 'zeros', 'eye', 'dirac', 'xavier_uniform', 'xavier_normal', 'kaiming_uniform', 'kaiming_normal', 'trunc_normal', 'orthogonal', 'sparse')\n",
    "            # # 'SpectralConv_initializer_param': 0.25, # (None, ) \n",
    "            # 'SpectralConv_non_linearity': 'gelu', # ('gelu', 'relu', 'silu', 'tanh', 'sigmoid', 'leakyrelu') \n",
    "\n",
    "            'use_cnn_skip': False, \n",
    "            # 'rm_fno_out': False, \n",
    "            # 'cnn_n_layers': 2,\n",
    "            # 'cnn_hidden_channels': 128,\n",
    "            # 'cnn_scale_mode': 'stationary_learning',\n",
    "            # 'cnn_scale_params': {'d': 2, 'alpha': 0.5},\n",
    "\n",
    "            'SpectralConv_use_cnn_skip': True,\n",
    "            'SpectralConv_cnn_n_layers': 4,\n",
    "            # 'SpectralConv_cnn_hidden_channels': 64,\n",
    "            'SpectralConv_cnn_hidden_channel_ratio': 4,\n",
    "            'SpectralConv_rm_low_pass_filter': False,\n",
    "            'SpectralConv_rm_fno_out': False,\n",
    "            'SpectralConv_rm_lpf_after_conv': False,\n",
    "            'SpectralConv_cnn_concat': True,\n",
    "            'Spectral_attention': None, # (None, 'SELayer', 'CBAM', 'BAM', 'SRM', 'GCModule', 'ECALayer', 'GCT')\n",
    "            # 'SpectralConv_cnn_scale_mode': 'cnn', # 'stationary_learning',\n",
    "            # 'SpectralConv_cnn_scale_params': {'d': 2, 'alpha': 0.5}, \n",
    "        \n",
    "        },\n",
    "        'device': device,\n",
    "    },\n",
    "    \n",
    "    'epochs': 50, \n",
    "    'optimizer': {\n",
    "        'loss_fn': 'h1',\n",
    "        'name': 'Adam',\n",
    "        'params': {\n",
    "            'lr': 1e-3,\n",
    "        },\n",
    "\n",
    "        'scheduler': {\n",
    "            'name': 'CosineAnnealingLR', \n",
    "        },\n",
    "    },\n",
    "    'data': [\n",
    "        # { 'nu': 0.001, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'fit',\n",
    "        # 'params': {\n",
    "        #     'base_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.001_n=128_fDNS=64/', \n",
    "        #     'dataset_name': f'2dHIT_nu=0.001_n=128_T=11.5_fDNS=64', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 64,\n",
    "        #     'num_workers': 0, \n",
    "\n",
    "        #     'Ndata_train':1000,  \n",
    "        #     'Ndata_val':50, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.001_n=128_fDNS=64/' + 'config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "       { 'nu': 0.000225, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "         'stage': 'fit',\n",
    "        'params': {\n",
    "            'base_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/', \n",
    "            'dataset_name': f'2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64', \n",
    "            \n",
    "            'n_input': 1, \n",
    "            'n_output':1, \n",
    "            'batch_size': 64,\n",
    "            'num_workers': 0, \n",
    "\n",
    "            'Ndata_train':1000,  \n",
    "            'Ndata_val':50, \n",
    "        },\n",
    "        'normalization': {\n",
    "            'normalization_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/' + 'config.yaml',\n",
    "        }\n",
    "        },\n",
    "        # { 'nu': 5e-04, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'fit',\n",
    "        # 'params': {\n",
    "        #     'base_path': 'D:\\RESEARCH/2DIso\\Data/nu=0.0005_n=256_fDNS=64/', \n",
    "        #     'dataset_name': f'2dHIT_nu=0.0005_n=256_T=12.0_fDNS=64', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 64,\n",
    "        #     'num_workers': 0, \n",
    "\n",
    "        #     'Ndata_train':500,  \n",
    "        #     'Ndata_val':50, \n",
    "        #     'load_data': False, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': 'D:\\RESEARCH/2DIso\\Data/nu=0.0005_n=256_fDNS=64/config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "        # { 'nu': 5e-05, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'fit',\n",
    "        # 'params': {\n",
    "        #     'base_path': '../Data/nu=5e-05_n=512_fDNS=64/', \n",
    "        #     'dataset_name': f'2dHIT_nu=5e-05_n=512_T=17.0_fDNS=64', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 64,\n",
    "        #     'num_workers': 0, \n",
    "\n",
    "        #     'Ndata_train':500,  \n",
    "        #     'Ndata_val':50, \n",
    "        #     'load_data': False, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': '../Data/nu=5e-05_n=512_fDNS=64/' + 'config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "\n",
    "        \n",
    "        {\n",
    "         'nu': 0.000225, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "         'stage': 'valid',\n",
    "        'params': {\n",
    "            'base_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256/', \n",
    "            'dataset_name': f'2dHIT_nu=0.000225_n=256_T=14.5', \n",
    "            \n",
    "            'n_input': 1, \n",
    "            'n_output':1, \n",
    "            'batch_size': 64,\n",
    "            'num_workers': 0, \n",
    "\n",
    "            'Ndata_val':1, \n",
    "            'load_data': False, \n",
    "        },\n",
    "        'normalization': {\n",
    "            'normalization_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256/' + 'config.yaml',\n",
    "        }\n",
    "        },\n",
    "        \n",
    "        # {\n",
    "        #  'nu': 5e-04, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'valid',\n",
    "        # 'params': {\n",
    "        #     'base_path': 'D:\\RESEARCH/2DIso\\Data/nu=0.0005_n=256/', \n",
    "        #     'dataset_name': f'2dHIT_nu=0.0005_n=256_T=12.0', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 64,\n",
    "        #     'num_workers': 0, \n",
    "\n",
    "        #     'Ndata_val':5, \n",
    "        #     'load_data': False, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': 'D:\\RESEARCH/2DIso\\Data/nu=0.0005_n=256/config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "        # { 'nu': 5e-05, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'valid',\n",
    "        # 'params': {\n",
    "        #     'base_path': '../Data/nu=5e-05_n=512/', \n",
    "        #     'dataset_name': f'2dHIT_nu=5e-05_n=512_T=17.0', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 16,\n",
    "        #     'num_workers': 0,\n",
    "\n",
    "        #     'Ndata_val':1,  \n",
    "        #     'load_data': False, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': '../Data/nu=5e-05_n=512/' + 'config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "        # { 'nu': 0.001, 'leadtime': 0.25, # 'idx_leadtime': 1, \n",
    "        #  'stage': 'valid',\n",
    "        # 'params': {\n",
    "        #     'base_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.001_n=128/', \n",
    "        #     'dataset_name': f'2dHIT_nu=0.001_n=128_T=11.5', \n",
    "            \n",
    "        #     'n_input': 1, \n",
    "        #     'n_output':1, \n",
    "        #     'batch_size': 64,\n",
    "        #     'num_workers': 0, \n",
    "\n",
    "        #     'Ndata_train':1000,  \n",
    "        #     'Ndata_val':50, \n",
    "        #     'load_data': False, \n",
    "        # },\n",
    "        # 'normalization': {\n",
    "        #     'normalization_path': r'D:\\RESEARCH\\2DIso\\Data\\nu=0.001_n=128/' + 'config.yaml',\n",
    "        # }\n",
    "        # },\n",
    "\n",
    "       \n",
    "    ]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CFD equation parameters ###\n",
    "integral_timescales = {\n",
    "    1e-3: 1.870162606239319,\n",
    "    5e-4: 1.5808453559875488,\n",
    "    0.000225: 1.3786518573760986, \n",
    "    1e-4: 1.3038111189,\n",
    "    5e-05: 1.15829598903656, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.CFDFunction import *\n",
    "from utils.Losses import *\n",
    "from utils.Plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import torch \n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "def high2low_box(\n",
    "    x: torch.Tensor,\n",
    "    scale_factors: Union[float, Sequence[float]] = 0.5,\n",
    "    *,\n",
    "    keepdim: bool = False,\n",
    "    dim: int = 2,\n",
    "    fft_norm: str = \"backward\",\n",
    "    last_var_axis: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Fourier‑domain box‑style scaling (down / up sampling).\n",
    "\n",
    "    The function supports tensors shaped either as\n",
    "        • (batch, channels, *spatial_dims)\n",
    "        • (batch, channels, *spatial_dims, num_var)\n",
    "\n",
    "    In the second case the last axis (``num_var``) is *not* included in the FFT\n",
    "    and therefore remains unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(scale_factors, float):\n",
    "        scale_factors = [scale_factors] * dim\n",
    "    scale_factors = list(scale_factors)\n",
    "    if len(scale_factors) != dim:\n",
    "        raise ValueError(\"`scale_factors` length must equal `dim`.\")\n",
    "\n",
    "    if x.ndim < dim + 2:\n",
    "        raise ValueError(\n",
    "            f\"Input tensor must have at least {dim + 2} dimensions (got {x.ndim}).\"\n",
    "        )\n",
    "\n",
    "    if last_var_axis:\n",
    "        spatial_axes = list(range(-(dim + 1), -1))\n",
    "    else:\n",
    "        spatial_axes = list(range(-dim, 0))\n",
    "    spatial_shape = [x.shape[i] for i in spatial_axes]\n",
    "\n",
    "    sf_tensor = torch.tensor(scale_factors, dtype=x.dtype, device=x.device)\n",
    "    if torch.allclose(sf_tensor, torch.ones_like(sf_tensor)):\n",
    "        return x.clone()\n",
    "\n",
    "    Fx = torch.fft.fftn(x, dim=spatial_axes, norm=fft_norm)\n",
    "\n",
    "    if (sf_tensor < 1).any():\n",
    "        Fx = torch.fft.fftshift(Fx, dim=spatial_axes)\n",
    "\n",
    "        if keepdim:\n",
    "            mask = torch.ones_like(Fx, dtype=torch.bool)\n",
    "            for rel_ax, (n, sf) in enumerate(zip(spatial_shape, scale_factors)):\n",
    "                trim = int(round((1 - sf) * n / 2))\n",
    "                if trim == 0:\n",
    "                    continue\n",
    "                abs_ax = spatial_axes[rel_ax] % Fx.ndim  # positive index\n",
    "                low = torch.arange(trim, device=x.device)\n",
    "                high = torch.arange(n - trim, n, device=x.device)\n",
    "                mask.index_fill_(abs_ax, low, False)\n",
    "                mask.index_fill_(abs_ax, high, False)\n",
    "            Fx = Fx * mask\n",
    "        else:\n",
    "            slices = [slice(None)] * Fx.ndim\n",
    "            for rel_ax, (n, sf) in enumerate(zip(spatial_shape, scale_factors)):\n",
    "                trim = int(round((1 - sf) * n / 2))\n",
    "                slices[spatial_axes[rel_ax]] = slice(trim, n - trim)\n",
    "            Fx = Fx[tuple(slices)]\n",
    "\n",
    "        Fx = torch.fft.ifftshift(Fx, dim=spatial_axes)\n",
    "\n",
    "    # ----------------------------- up‑sampling branch -------------------------\n",
    "    if (sf_tensor > 1).any():\n",
    "        Fx = torch.fft.fftshift(Fx, dim=spatial_axes)\n",
    "\n",
    "        # F.pad pads the *last* k dims; build list accordingly\n",
    "        last_axes = list(range(-len(spatial_axes) - (1 if last_var_axis else 0), 0))\n",
    "        pads: List[int] = []\n",
    "        for ax in Reflectiond(last_axes):\n",
    "            if ax in spatial_axes:\n",
    "                rel = spatial_axes.index(ax)\n",
    "                n = spatial_shape[rel]\n",
    "                sf = scale_factors[rel]\n",
    "                extra = int(round((sf - 1) * n))\n",
    "                pads.extend([extra // 2, extra - extra // 2])\n",
    "            else:  # var axis → no pad\n",
    "                pads.extend([0, 0])\n",
    "        Fx = F.pad(Fx, pads, mode=\"constant\", value=0.0)\n",
    "        Fx = torch.fft.ifftshift(Fx, dim=spatial_axes)\n",
    "\n",
    "    # --------------------------------------------------- inverse FFT ----------\n",
    "    x_out = torch.fft.ifftn(Fx, dim=spatial_axes, norm=fft_norm).real\n",
    "\n",
    "    # ------------------------------ match statistics --------------------------\n",
    "    def _mom(t: torch.Tensor):\n",
    "        mean = t.mean(dim=spatial_axes, keepdim=True)\n",
    "        std = t.std(dim=spatial_axes, unbiased=False, keepdim=True).clamp_min(1e-12)\n",
    "        return mean, std\n",
    "\n",
    "    mean_in, std_in = _mom(x)\n",
    "    mean_out, std_out = _mom(x_out)\n",
    "\n",
    "    x_out = (x_out - mean_out) / std_out * std_in + mean_in\n",
    "    return x_out\n",
    "\n",
    "class HIT2dDataset(Dataset):\n",
    "    def __init__(self, \n",
    "        path: Optional[str] = None,\n",
    "        base_path: Optional[str] = None,\n",
    "        dataset_name: Optional[str] = None,\n",
    "        split_name: Optional[str] = None,\n",
    "\n",
    "        target_path: Optional[str] = None,\n",
    "        target_base_path: Optional[str] = None,\n",
    "        target_dataset_name: Optional[str] = None,\n",
    "        \n",
    "        normalization:Optional[callable] = None,\n",
    "        transform:Optional[callable] = None,\n",
    "\n",
    "        n_input: int = 1,\n",
    "        n_output: int = 1,\n",
    "        n_stride: int = 0,\n",
    "        max_rollout_steps=100,\n",
    "        max_n_sim: Optional[int] = None,\n",
    "        # batch_size:int=32, \n",
    "        \n",
    "        # num_iteration_per_data:int=None, \n",
    "        # isDataAugmentation:bool=False,\n",
    "        load_data:bool=True,\n",
    "        verbose:bool=True,\n",
    "        **kwargs, \n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.base_path = base_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.split_name = split_name\n",
    "        if not path: \n",
    "            path = os.path.join(self.base_path, self.split_name, self.dataset_name) # f\"{self.base_path}/{self.split_name}/{self.dataset_name}*\"\n",
    "        self.path = sorted(glob.glob(f\"{path}*\"))\n",
    "        assert self.path, f\"Error: Dataset path {path} does not exist.\"\n",
    "\n",
    "        self.target_path = self.path\n",
    "        if target_path is not None or target_base_path is not None:\n",
    "            self.target_base_path = target_base_path\n",
    "            self.target_dataset_name = target_dataset_name\n",
    "            self.target_split_name = split_name\n",
    "            if not target_path: \n",
    "                target_path = os.path.join(self.target_base_path, self.split_name, self.target_dataset_name) # f\"{self.base_path}/{self.split_name}/{self.dataset_name}*\"\n",
    "            self.target_path = sorted(glob.glob(f\"{target_path}*\"))\n",
    "            assert self.target_path, f\"Error: Dataset path {target_path} does not exist.\"\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.transform = transform\n",
    "\n",
    "        self.max_rollout_steps = max_rollout_steps\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.n_stride = n_stride\n",
    "        self.max_n_sim = max_n_sim if max_n_sim else np.inf\n",
    "        \n",
    "        self.verbose=verbose\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        self._build_metadata()\n",
    "        self._calc_len()\n",
    "        self.load_data = load_data\n",
    "        if load_data:\n",
    "            self.data = self._load_data(self.path)\n",
    "            self.target_data = self._load_data(self.target_path) if self.target_path is not None else self.data\n",
    "\n",
    "    def _calc_len(self):\n",
    "        self.n_sim = min(self.max_n_sim, sum(self.n_sim_per_file)) # self.n_sim = sum(self.n_sim_per_file) # len(self.data)\n",
    "        self.n_steps_per_sim = self.Nt\n",
    "        self.n_windows_per_sim = self.n_steps_per_sim - (self.n_input + self.n_output + self.n_stride) + 1\n",
    "        self.len = self.n_sim * self.n_windows_per_sim\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx:int):\n",
    "        data = self._load_one_sample(idx)\n",
    "        data = self._preprocess_data(data)\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.normalization:\n",
    "            data = self.normalization(data)      \n",
    "        data = self._postprocess_data(data)\n",
    "        return data\n",
    "    \n",
    "    def _load_one_sample(self, idx:int):\n",
    "        isim = idx // self.n_windows_per_sim\n",
    "        it = idx % self.n_windows_per_sim\n",
    "        if self.load_data:\n",
    "            data = self.data[isim, it:it + self.n_input] # (n_in, channels, *datashape)\n",
    "            target = self.target_data[isim, it + self.n_input + self.n_stride:it + self.n_input + self.n_stride + self.n_output] # (n_out, channels, *datashape)\n",
    "        else: \n",
    "            for i in range(len(self.n_sim_per_file)):\n",
    "                ifile = i \n",
    "                if isim < sum(self.n_sim_per_file[:i+1]): break \n",
    "            \n",
    "            isim = isim - sum(self.n_sim_per_file[:i])\n",
    "            with h5py.File(self.path[ifile], 'r') as f:\n",
    "                data = f[\"fields\"]['vorticity'][isim, it:it + self.n_input] # (n_in, channels, *datashape)\n",
    "                data = torch.from_numpy(data)\n",
    "                \n",
    "            with h5py.File(self.target_path[ifile], 'r') as f:\n",
    "                target = f[\"fields\"]['vorticity'][isim, it + self.n_input + self.n_stride:it + self.n_input + self.n_stride + self.n_output] # (n_out, channels, *datashape)\n",
    "                target = torch.from_numpy(target)\n",
    "        return data, target\n",
    "\n",
    "    def _load_data(self, path=None,):\n",
    "        if not path: path = self.path\n",
    "        data = []\n",
    "        self.n_sim = 0\n",
    "        if self.verbose: start_time = time.time()\n",
    "        for p in path:\n",
    "            with h5py.File(p, 'r') as f:\n",
    "                _n_sim = f.attrs[\"n_trajectories\"]\n",
    "                \n",
    "                end = min(self.max_n_sim - self.n_sim, _n_sim)\n",
    "                vorticity = f[\"fields\"]['vorticity'][:end]# vorticity = f[\"fields\"]['vorticity'][:]\n",
    "                if self.verbose: \n",
    "                    print(f'Data Loaded from{p}. shape: {vorticity.shape}, memory: {vorticity.nbytes/1e6} (MB)')\n",
    "            \n",
    "            data.append(vorticity)\n",
    "            self.n_sim += len(vorticity)\n",
    "            if self.max_n_sim <= self.n_sim: break\n",
    "            \n",
    "        data = np.concatenate(data, axis=0)\n",
    "        memory = data.nbytes\n",
    "        data = torch.from_numpy(data)\n",
    "        # self.data = self.data.reshape(self.data.size(0) * self.data.size(1), self.data.size()[2:]) # self.data = torch.concat(self.data, dim=0)\n",
    "        if self.verbose: print(f'Data Loaded. shape: {data.shape}, dtype: {data.dtype}, time: {time.time() - start_time} (sec), memory: {memory/1e6} (MB)')\n",
    "        self._calc_len()\n",
    "        return data\n",
    "        \n",
    "    def _build_metadata(self):\n",
    "        \n",
    "        with h5py.File(self.path[0], 'r') as f:\n",
    "            self.nu = f['scalars']['nu'][()]\n",
    "\n",
    "            self.t = t = f[\"dimensions\"][\"t\"][:]\n",
    "            self.x = x = f[\"dimensions\"][\"x\"][:]\n",
    "            self.y = y = f[\"dimensions\"][\"y\"][:]\n",
    "            self.X, self.Y = np.meshgrid(x, y)\n",
    "\n",
    "            self.Lx = x[-1] - x[0]\n",
    "            self.Ly = y[-1] - y[0]\n",
    "            self.dx = x[1] - x[0]\n",
    "            self.dy = y[1] - y[0]\n",
    "            self.Nx = len(x)\n",
    "            self.Ny = len(y)\n",
    "            self.dt = t[1] - t[0]\n",
    "            self.Nt = len(t)\n",
    "            self.T = t[-1]\n",
    "            self.t0 = t[0]\n",
    "\n",
    "        self.n_sim_per_file = []\n",
    "        for path in self.path:\n",
    "            with h5py.File(path, 'r') as f:\n",
    "                n_sim = f.attrs[\"n_trajectories\"]\n",
    "                self.n_sim_per_file.append(n_sim)\n",
    "                if self.max_n_sim <= sum(self.n_sim_per_file): break\n",
    "        \n",
    "        self.metadata = {\n",
    "            'nu': self.nu,\n",
    "\n",
    "            'Lx': self.Lx,\n",
    "            'Ly': self.Ly,\n",
    "            'dx': self.dx,\n",
    "            'dy': self.dy,\n",
    "            'Nx': self.Nx, \n",
    "            'Ny': self.Ny,\n",
    "            'x': self.x,\n",
    "            'y': self.y,\n",
    "\n",
    "            'dt': self.dt,\n",
    "            'Nt': self.Nt,\n",
    "            'T': self.T,\n",
    "            't0': self.t0,\n",
    "            't': self.t,\n",
    "        }\n",
    "        if self.verbose:\n",
    "            print(f\"Loaded dataset metadata: {self.metadata.keys()}\")\n",
    "        return self.metadata\n",
    "    \n",
    "    def _preprocess_data(self, data):\n",
    "        data, target = data\n",
    "\n",
    "        x = [data, target] # x = torch.cat([data, target], dim=0)\n",
    "\n",
    "        return x\n",
    "    def _postprocess_data(self, data):\n",
    "        data, target = data[0], data[1]\n",
    "\n",
    "        # data = data.flatten(0, 1) # data.reshape(data.shape[0] * data.shape[1], *data.shape[2:]) # (n_in * channels, *datashape)\n",
    "        # target = target.flatten(0, 1) # target.reshape(target.shape[0] * target.shape[1], *target.shape[2:]) # (n_out * channels, *datashape)\n",
    "\n",
    "        return data, target\n",
    "\n",
    "class CustomDataModule:\n",
    "    def __init__(self, \n",
    "                 batch_size:int=32, \n",
    "                 Ndata_train:int=500, \n",
    "                 Ndata_val:int=50, \n",
    "                 Ndata_test:int=100, \n",
    "                 num_workers:int=0,\n",
    "                 transform:Optional[callable]=None,\n",
    "                 normalization:Optional[callable]=None,\n",
    "                 *args, **kwargs\n",
    "                 ):\n",
    "        self.batch_size = batch_size\n",
    "        self.Ndata_train = Ndata_train\n",
    "        self.Ndata_val = Ndata_val\n",
    "        self.Ndata_test = Ndata_test\n",
    "\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transform\n",
    "        self.normalization = normalization\n",
    "\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    \n",
    "    def setup(self, stage:str=None):\n",
    "        if stage in ['train', 'fit', None]:\n",
    "            self.train_dataset = HIT2dDataset(split_name='train', max_n_sim=self.Ndata_train, transform=self.transform, normalization=self.normalization, *self.args, **self.kwargs, )\n",
    "            print(f'Train dataset: {len(self.train_dataset)}')\n",
    "            \n",
    "        if stage in ['valid', 'fit', None]:\n",
    "            self.val_dataset = HIT2dDataset(split_name='valid', max_n_sim=self.Ndata_val, transform=None, normalization=self.normalization, *self.args, **self.kwargs, )\n",
    "            print(f'Val dataset: {len(self.val_dataset)}')\n",
    "\n",
    "        if stage in ['test', None]:\n",
    "            self.test_dataset = HIT2dDataset(split_name='valid', max_n_sim=self.Ndata_test, transform=None, normalization=self.normalization, *self.args, **self.kwargs, )\n",
    "            print(f'Test dataset: {len(self.test_dataset)}')\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.train_dataset is None: self.setup(stage='train')\n",
    "        return torch.utils.data.DataLoader(self.train_dataset, \n",
    "                                           batch_size = self.batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=self.num_workers, \n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=True, \n",
    "                                           )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        if self.val_dataset is None: self.setup(stage='valid')\n",
    "        return torch.utils.data.DataLoader(self.val_dataset, \n",
    "                                           batch_size = self.batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=self.num_workers,\n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=True,\n",
    "                                           )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.test_dataset is None:self.setup(stage='test')\n",
    "        test_batch_size = self.batch_size # self.test_dataset.n_windows_per_sim # // 8\n",
    "        return torch.utils.data.DataLoader(self.test_dataset, \n",
    "                                           batch_size = test_batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=self.num_workers, \n",
    "                                           pin_memory=True,\n",
    "                                           drop_last=True,\n",
    "                                           )\n",
    "\n",
    "\n",
    "class RandomShift(nn.Module):\n",
    "    def __init__(self, \n",
    "        shifts:Union[float, Sequence[float]]=(0.5, 0.5), \n",
    "        dims:Union[int, Sequence[int]]=(-2, -1),\n",
    "        *args, **kwargs\n",
    "        ):\n",
    "        super(RandomShift, self).__init__()\n",
    "        self.shifts = shifts\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, \n",
    "        x, \n",
    "        shifts:Union[float, Sequence[float]]=None, \n",
    "        dims:Union[int, Sequence[int]]=None, \n",
    "        ):\n",
    "        if shifts is None: shifts = self.shifts\n",
    "        if dims is None: dims = self.dims\n",
    "        \n",
    "        return self.RandomShift(x, shifts=self.shifts, dims=self.dims)\n",
    "    \n",
    "    def RandomShift(self,\n",
    "        x, \n",
    "        shifts:Union[float, Sequence[float]]=(0.5, 0.5), \n",
    "        dims:Union[int, Sequence[int]]=(-2, -1)\n",
    "        ):\n",
    "        '''\n",
    "        Random shift the input tensor along the spatial dimensions. \n",
    "        Parameters:\n",
    "        - x (torch.tensor): input tensor, shape \n",
    "        - shifts (float or sequence of float): maximum shift fraction along each dimension. \n",
    "            If float, the same shift fraction is applied to all dimensions.\n",
    "            If sequence of float, the length must be equal to the number of spatial dimensions.\n",
    "            The shift fraction is relative to the size of the dimension.\n",
    "        - dims (int or sequence of int): dimensions to apply the shift. \n",
    "            If int, the same dimension is applied to all spatial dimensions.\n",
    "            If sequence of int, the length must be equal to the number of spatial dimensions.\n",
    "        \n",
    "        Returns:\n",
    "        - x (torch.tensor): shifted tensor, shape \n",
    "        '''\n",
    "        if isinstance(shifts, float): shifts = [shifts] * len(dims)\n",
    "        assert len(shifts) == len(dims), \"Length of shifts and dims must be equal to the number of spatial dimensions.\"\n",
    "\n",
    "        shifts = [int(np.random.uniform(-s, s) * x.shape[d]) for s, d in zip(shifts, dims)]\n",
    "        x = torch.roll(x, shifts=shifts, dims=dims)\n",
    "        return x\n",
    "\n",
    "class Reflection(nn.Module):\n",
    "    def __init__(self, \n",
    "        p: float=0.5,\n",
    "        dims:Union[int, Sequence[int]]=(-2, -1),\n",
    "        *args, **kwargs\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, \n",
    "        x, \n",
    "        p = None, \n",
    "        dims:Union[int, Sequence[int]]=None, \n",
    "        ):\n",
    "        if dims is None: dims = self.dims\n",
    "        if p is None: p = self.p\n",
    "        \n",
    "        return self.Reflection(x, p=p, dims=self.dims)\n",
    "    \n",
    "    def Reflection(self,\n",
    "        x, \n",
    "        p: float=0.5, \n",
    "        dims:Union[int, Sequence[int]]=(-2, -1)\n",
    "        ):\n",
    "        '''\n",
    "        Reflection the input tensor along the spatial dimensions. \n",
    "        Parameters:\n",
    "        - x (torch.tensor): input tensor, shape \n",
    "        - dims (int or sequence of int): dimensions to apply the Reflection. \n",
    "            If int, the same dimension is applied to all spatial dimensions.\n",
    "            If sequence of int, the length must be equal to the number of spatial dimensions.\n",
    "        \n",
    "        Returns:\n",
    "        - x (torch.tensor): Reflection tensor, shape \n",
    "        '''\n",
    "        if isinstance(dims, int): dims = [dims]\n",
    "        \n",
    "        for d in dims:\n",
    "            if np.random.rand() < p: x = torch.flip(x, dims=(d,))\n",
    "        return x\n",
    "\n",
    "class Reverse(nn.Module):\n",
    "    def __init__(self, \n",
    "        p: float=0.5,\n",
    "        *args, **kwargs\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, \n",
    "        x, \n",
    "        p = None, \n",
    "        ):\n",
    "        if p is None: p = self.p\n",
    "        \n",
    "        return self.Reverse(x, p=p)\n",
    "    \n",
    "    def Reverse(self,\n",
    "        x, \n",
    "        p: float=0.5, \n",
    "        ):\n",
    "        '''\n",
    "        Reverse the input tensor along the time dimension. \n",
    "        Parameters:\n",
    "        - x (torch.tensor): input tensor, shape \n",
    "        - dim (int): dimension to apply the Reverse. \n",
    "        \n",
    "        Returns:\n",
    "        - x (torch.tensor): Reverse tensor, shape \n",
    "        '''\n",
    "        if np.random.rand() < p: x = -x \n",
    "        return x\n",
    "    \n",
    "class CustomTransform(nn.Module):\n",
    "    def __init__(self, \n",
    "                *args, **kwargs, \n",
    "                ):\n",
    "        super(CustomTransform, self).__init__()\n",
    "        # self.file_dir = file_dir\n",
    "        # self.Ndata = Ndata\n",
    "        self.kwargs = kwargs \n",
    "        self.build_transform()\n",
    "\n",
    "    def build_transform(self):\n",
    "        self.transforms = nn.Sequential(\n",
    "            RandomShift(shifts=0.5, dims=(-2, -1)),\n",
    "            Reflection(p=0.5, dims=(-2, -1)),\n",
    "            Reverse(p=0.5),\n",
    "        )\n",
    "        return self.transforms\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transform(x)\n",
    "        return x\n",
    "    \n",
    "    def transform(self, x):\n",
    "        for t in self.transforms:\n",
    "            x = t(x)\n",
    "        return x\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        for t in self.transforms[::-1]:\n",
    "            x = t.inverse_transform(x)\n",
    "        return x\n",
    "\n",
    "class Standardize(nn.Module):\n",
    "    def __init__(self, \n",
    "        mean:Optional[float]=None, std:Optional[float]=None, \n",
    "        normalization_path:Optional[str]=None,\n",
    "\n",
    "        base_path: Optional[str] = None,\n",
    "        dataset_name: Optional[str] = None,\n",
    "        split_name: Optional[str] = None,\n",
    "        *args, **kwargs, \n",
    "        ):\n",
    "        super(Standardize, self).__init__()\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        ## build_transform\n",
    "        if mean is not None and std is not None: \n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "        elif normalization_path is not None:\n",
    "            self.load_stats(normalization_path)\n",
    "        elif dataset_name is not None: \n",
    "            path = os.path.join(base_path, split_name, dataset_name)\n",
    "            self.calc_stats_from_dataset(path)\n",
    "        else:\n",
    "            assert False, \"Error: must provide either (mean, std), normalization_path, or (base_path, dataset_name, split_name) to calculate mean and std.\"\n",
    "    \n",
    "    def load_stats(self, path=None):\n",
    "        assert os.path.exists(path), f\"Error: normalization path {path} does not exist.\"\n",
    "        with open(path, \"r\") as f:\n",
    "            stats = yaml.safe_load(f)['statistics']\n",
    "\n",
    "            self.mean = stats['mean']\n",
    "            self.std = stats['std']\n",
    "        return self.mean, self.std\n",
    "    \n",
    "    def calc_stats_from_dataset(self, path=None):\n",
    "        dataset = HIT2dDataset(path=path, load_data=True, *self.args, **self.kwargs).load_data()\n",
    "        self.mean = dataset.data.mean().item()\n",
    "        self.std = dataset.data.std().item()\n",
    "        return self.mean, self.std\n",
    "\n",
    "    def forward(self, x):\n",
    "        data, target = x\n",
    "        data = self.normalize(data, params=None)[0]\n",
    "        target = self.normalize(target, params=None)[0]\n",
    "        return [data, target]\n",
    "    \n",
    "    def normalize(self, inpt: Any, params: Dict[str, Any]):\n",
    "        return (inpt - self.mean) / self.std\n",
    "\n",
    "    def denormalize(self, inpt: Any, params: Dict[str, Any]):\n",
    "        return inpt * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils.CFDFunction import calc_energy_spectrum\n",
    "from utils.Plots import plot_spectrum\n",
    "\n",
    "class Hook(nn.Module):\n",
    "    def __init__(self, hook_every_n_iter:int=1):\n",
    "        super(Hook, self).__init__()\n",
    "        self.iteration = 0\n",
    "        self.data = {}\n",
    "        self.data['spectrum'] = {}\n",
    "        self.hook_every_n_iter = hook_every_n_iter\n",
    "        self.prefix = ''\n",
    "\n",
    "    def open_hook(self, prefix:str=''):\n",
    "        # if self.iteration % self.hook_every_n_iter != 0: return \n",
    "        self.data = {}\n",
    "        self.data['spectrum'] = {}\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def close_hook(self, fname:str=''):\n",
    "        # if self.iteration % self.hook_every_n_iter != 0: return \n",
    "        spectrums = list(self.data['spectrum'].values())\n",
    "        title = list(self.data['spectrum'].keys())\n",
    "\n",
    "        plot_spectrum(spectrum1=spectrums[0], spectrum2=spectrums[1:], \n",
    "                      figsize=(min(len(spectrums), 5)*6, (len(spectrums) // 5 + 1 + int(len(spectrums) % 5 == 0))*6),\n",
    "                      suptitle=f'Spectrum at iteration {self.iteration} - {self.prefix}',\n",
    "                      titles=title, overlapping=False, \n",
    "                      )\n",
    "        plt.savefig(fname+'.png', dpi=300)\n",
    "        plt.close('all')\n",
    "    \n",
    "    def set_prefix(self, name:str=''):\n",
    "        self.prefix = name\n",
    "\n",
    "    def step(self):\n",
    "        self.iteration += 1\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x, name:str='', model:nn.Module=None):\n",
    "        # if self.iteration % self.hook_every_n_iter != 0: return \n",
    "        \n",
    "        ## spectrum\n",
    "        _spectrum = calc_energy_spectrum(x, dim=(-2, -1), channel_dim=1).sum(dim=0)\n",
    "        if self.prefix: \n",
    "            name = f'{self.prefix}_{name}'\n",
    "        self.data['spectrum'][name] = _spectrum.detach().cpu().numpy()\n",
    "\n",
    "hook = Hook(hook_every_n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, Tuple, Dict, Any, Literal, Union, Iterable\n",
    "\n",
    "from utils.neuraloperator import SpectralConv as BaseSpectralConv\n",
    "from utils.neuraloperator import FNOBlocks as BaseFNOBlocks\n",
    "from utils.neuraloperator import FNO as BaseFNO\n",
    "\n",
    "from utils.refer.WTConv_main.wtconv.wtconv2d import WTConv2d\n",
    "\n",
    "class CNO_activation(nn.Module):\n",
    "    def __init__(self, \n",
    "        out_shape: Optional[tuple] = None,\n",
    "        activation: callable = F.gelu,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.out_shape = out_shape\n",
    "        self.act = activation\n",
    "\n",
    "    def forward(self, x: torch.Tensor, out_shape:Optional[tuple]=None) -> torch.Tensor:\n",
    "        in_size = [2 * s for s in x.shape[2:]]\n",
    "        out_shape = list(x.shape[2:]) if out_shape is None and self.out_shape is None else self.out_shape if out_shape is None else out_shape\n",
    "\n",
    "        x = F.interpolate(x, size=in_size, mode='bilinear', align_corners=True)\n",
    "        x = self.act(x)\n",
    "        x = F.interpolate(x, size=out_shape, mode='bilinear', align_corners=True)\n",
    "        return x\n",
    "    \n",
    "class Dealiasing_activation(nn.Module):\n",
    "    def __init__(self, \n",
    "        scale: float = 3/2,\n",
    "        activation: callable = F.gelu,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.act = activation\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.dealiasing(x, scale=self.scale, fn=self.act)\n",
    "        return x\n",
    "\n",
    "    def dealiasing(self, x: torch.Tensor, \n",
    "                scale: float = 3/2, \n",
    "                fn=None):\n",
    "        dim = list(np.arange(2, len(x.shape)))\n",
    "        # original spatial size\n",
    "        orig_size = [x.size(d) for d in dim]\n",
    "        new_size = [int(s * scale) for s in orig_size]\n",
    "        idx = [slice(None), slice(None)]\n",
    "        for n, o in zip(new_size, orig_size):\n",
    "            start = (n - o) // 2\n",
    "            end = start + o\n",
    "            idx.append(slice(start, end))\n",
    "        new_size = list(x.shape[:2]) + new_size\n",
    "\n",
    "        # (1) FFT in low-res\n",
    "        Fx = torch.fft.fftn(x, dim=dim)\n",
    "        Fx = torch.fft.fftshift(Fx, dim=dim)\n",
    "        Fx_pad = torch.zeros(new_size, dtype=Fx.dtype, device=x.device)\n",
    "        Fx_pad[idx] = Fx\n",
    "\n",
    "        x_pad = torch.fft.ifftn(Fx_pad, dim=dim).real\n",
    "\n",
    "        x_pad = fn(x_pad)\n",
    "\n",
    "        Fx_pad = torch.fft.fftn(x_pad, dim=dim)\n",
    "        Fx_pad = torch.fft.fftshift(Fx_pad, dim=dim)\n",
    "\n",
    "        Fx = Fx_pad[idx]\n",
    "        Fx = torch.fft.fftshift(Fx, dim=dim)\n",
    "        x = torch.fft.ifftn(Fx, dim=dim).real  # often want real\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "def init_t_xy(end_x: int, end_y: int):\n",
    "    t = torch.arange(end_x * end_y, dtype=torch.float32)\n",
    "    t_x = (t % end_x).float()\n",
    "    t_y = torch.div(t, end_x, rounding_mode='floor').float()\n",
    "    return t_x, t_y\n",
    "\n",
    "def compute_mixed_cis(freqs: torch.Tensor, t_x: torch.Tensor, t_y: torch.Tensor, num_heads: int):\n",
    "    N = t_x.shape[0]\n",
    "    # No float 16 for this range\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        freqs_x = (t_x.unsqueeze(-1) @ freqs[0].unsqueeze(-2)).view(N, num_heads, -1).permute(1, 0, 2)\n",
    "        freqs_y = (t_y.unsqueeze(-1) @ freqs[1].unsqueeze(-2)).view(N, num_heads, -1).permute(1, 0, 2)\n",
    "        freqs_cis = torch.polar(torch.ones_like(freqs_x), freqs_x + freqs_y)\n",
    "    return freqs_cis\n",
    "\n",
    "def init_2d_freqs(dim: int, num_heads: int, theta: float = 10.0, rotate: bool = True):\n",
    "    freqs_x = []\n",
    "    freqs_y = []\n",
    "    mag = 1 / (theta ** (torch.arange(0, dim, 4)[: (dim // 4)].float() / dim))\n",
    "    for i in range(num_heads):\n",
    "        angles = torch.rand(1) * 2 * torch.pi if rotate else torch.zeros(1)        \n",
    "        fx = torch.cat([mag * torch.cos(angles), mag * torch.cos(torch.pi/2 + angles)], dim=-1)\n",
    "        fy = torch.cat([mag * torch.sin(angles), mag * torch.sin(torch.pi/2 + angles)], dim=-1)\n",
    "        freqs_x.append(fx)\n",
    "        freqs_y.append(fy)\n",
    "    freqs_x = torch.stack(freqs_x, dim=0)\n",
    "    freqs_y = torch.stack(freqs_y, dim=0)\n",
    "    freqs = torch.stack([freqs_x, freqs_y], dim=0)\n",
    "    return freqs\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    if freqs_cis.ndim == 2:\n",
    "        freqs_cis = freqs_cis.unsqueeze(0)\n",
    "        return freqs_cis\n",
    "    if freqs_cis.ndim == 3 and freqs_cis.shape[0] == 1: return freqs_cis\n",
    "\n",
    "    if freqs_cis.shape == (x.shape[-2], x.shape[-1]):\n",
    "        shape = [d if i >= ndim-2 else 1 for i, d in enumerate(x.shape)]\n",
    "    elif freqs_cis.shape == (x.shape[-3], x.shape[-2], x.shape[-1]):\n",
    "        shape = [d if i >= ndim-3 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "def apply_rotary_emb(x: torch.Tensor, freqs_cis: torch.Tensor):\n",
    "    x = x.contiguous()\n",
    "    x_ = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, x_)\n",
    "    x_out = torch.view_as_real(x_ * freqs_cis).flatten(3)\n",
    "    return x_out.type_as(x).to(x.device)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, *args, out_channels:int, rope_theta=10.0, in_channels:Optional[int]=None, isproj:bool=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        assert out_channels % 4 == 0\n",
    "        self.out_channels = out_channels\n",
    "        self.num_heads = 1\n",
    "        self.rope_theta = rope_theta\n",
    "\n",
    "        self.compute_cis = partial(compute_mixed_cis, num_heads=self.num_heads)     \n",
    "        freqs = init_2d_freqs(\n",
    "            dim=self.out_channels // self.num_heads, num_heads=self.num_heads, theta=rope_theta, \n",
    "            rotate=True\n",
    "        ).view(2, -1)\n",
    "        self.freqs = nn.Parameter(freqs, requires_grad=True) # (2, out_channels // 2)\n",
    "        \n",
    "        # t_x, t_y = init_t_xy(end_x=n_x, end_y=n_y) # (n_x * n_y)\n",
    "        # self.register_buffer('freqs_t_x', t_x)\n",
    "        # self.register_buffer('freqs_t_y', t_y)\n",
    "\n",
    "        self.isproj = isproj\n",
    "        if self.isproj: \n",
    "            if in_channels is None: in_channels = out_channels \n",
    "            self.proj = nn.Linear(in_channels, out_channels) \n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        B, C, *data_shape = x.shape\n",
    "        N = torch.prod(torch.tensor(data_shape)).item()\n",
    "        \n",
    "        x = x.view(B, C, N).permute(0, 2, 1) # (B, N, C)\n",
    "        if self.isproj: x = self.proj(x)\n",
    "\n",
    "        ## Rotary position embedding\n",
    "        \n",
    "        # if self.freqs_t_x.shape[0] != x.shape[1] - 1:\n",
    "        if not hasattr(self, 'freqs_t_x') or self.freqs_t_x.shape[0] != x.shape[1]:\n",
    "            n_x, n_y = data_shape[-2:]\n",
    "            t_x, t_y = init_t_xy(end_x=n_x, end_y=n_y)\n",
    "            t_x, t_y = t_x.to(x.device), t_y.to(x.device)\n",
    "            self.freqs_t_x, self.freqs_t_y = t_x, t_y\n",
    "        else: \n",
    "            t_x, t_y = self.freqs_t_x, self.freqs_t_y\n",
    "        freqs_cis = self.compute_cis(self.freqs, t_x, t_y)\n",
    "\n",
    "        x = apply_rotary_emb(x, freqs_cis)\n",
    "\n",
    "        out = x.permute(0,2,1,3).reshape(B, self.out_channels, *data_shape)\n",
    "        return out\n",
    "    \n",
    "def positionalencoding2d(x:Tensor, d_model:int=None):\n",
    "    \"\"\"\n",
    "    https://github.com/wzlxjtu/PositionalEncoding2D/blob/master/positionalembedding2d.py\n",
    "    :param d_model: dimension of the model\n",
    "    :param height: height of the positions\n",
    "    :param width: width of the positions\n",
    "    :return: d_model*height*width position matrix\n",
    "    \"\"\"\n",
    "    batch_size, d_model, height, width = x.shape\n",
    "    n_positional_dims = 2\n",
    "    if d_model % 4 != 0:\n",
    "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                        \"odd dimension (got dim={:d})\".format(d_model))\n",
    "    pe = torch.zeros(d_model, height, width)\n",
    "    # Each dimension use half of d_model\n",
    "\n",
    "    div_term = torch.exp((torch.arange(0., d_model, 2) / d_model) *\n",
    "                        -(math.log(10000.0))).to(x.device)\n",
    "    pos_w = torch.linspace(0, 1, steps=width, device=x.device).unsqueeze(1) # torch.arange(0., width).unsqueeze(1) # \n",
    "    pos_h = torch.linspace(0, 1, steps=height, device=x.device).unsqueeze(1)\n",
    "    pe[0::2, :, :] = torch.cos(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1) - torch.sin(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    \n",
    "    pe[1::2, :, :] = torch.sin(pos_w * div_term).transpose(0, 1).unsqueeze(1).repeat(1, height, 1) - torch.cos(pos_h * div_term).transpose(0, 1).unsqueeze(2).repeat(1, 1, width)\n",
    "    pe = pe.unsqueeze(0).repeat(batch_size, 1, *[1]*n_positional_dims)\n",
    "    return pe\n",
    "\n",
    "def _positional_embedding(x):\n",
    "    '''\n",
    "    Append spatial positional embedding to the input tensor.\n",
    "    Parameters:\n",
    "    - x (torch.tensor): input tensor, shape (batch_size, channels, *spatial_shape)\n",
    "    \n",
    "    Returns:\n",
    "    - x (torch.tensor): output tensor with positional embedding, shape (batch_size, channels + n_positional_dims, *spatial_shape)\n",
    "    '''\n",
    "    batch_size = x.shape[0]\n",
    "    spatial_shape = x.shape[2:]\n",
    "    n_positional_dims = len(spatial_shape)\n",
    "\n",
    "    # Create coordinate grids\n",
    "    grids = torch.meshgrid([torch.linspace(0, 1, steps=s, device=x.device) for s in spatial_shape], indexing='ij')\n",
    "    # Stack and expand to batch size\n",
    "    pos_embedding = torch.stack(grids, dim=0).unsqueeze(0).repeat(batch_size, 1, *[1]*n_positional_dims)\n",
    "\n",
    "    return pos_embedding\n",
    "\n",
    "class CustomConv2d(nn.Module):\n",
    "    def __init__(self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: int = 3, \n",
    "        stride: int = 1, \n",
    "        padding: int = 1,\n",
    "        padding_mode: Union[str, Iterable] = 'circular',\n",
    "        dilation: int = 1,\n",
    "        bias: bool = True,\n",
    "        groups: int = 1,\n",
    "        device: Optional[torch.device] = None,\n",
    "        dtype: Optional[torch.dtype] = None,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.padding = padding\n",
    "        self.padding_mode = padding_mode\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding, padding_mode=padding_mode, dilation=dilation, groups=groups, bias=bias, device=device, dtype=dtype)\n",
    "\n",
    "    def calc_pad(self, input_shape, output_shape):\n",
    "        if len(input_shape) > len(output_shape):\n",
    "            input_shape = input_shape[-len(output_shape):]\n",
    "        pad = []\n",
    "        for in_size, out_size in zip(reversed(input_shape), reversed(output_shape)):\n",
    "            total_pad = max(out_size - in_size, 0)\n",
    "            pad_left = total_pad // 2 \n",
    "            pad_right = total_pad - pad_left # If odd, pad more on the right\n",
    "            pad.extend([pad_left, pad_right])\n",
    "        return tuple(pad)\n",
    "\n",
    "    def pad(self, x, pad, mode='constant', value=0):\n",
    "        dim = len(pad) // 2 \n",
    "\n",
    "        if mode == 'circular':\n",
    "            # x 마지막 dim개의 크기만 보고 반복\n",
    "            input_shape = x.shape[-dim:]\n",
    "            new_sizes = []\n",
    "            reps = []\n",
    "            for i in range(dim):\n",
    "                left = pad[2*i]\n",
    "                right = pad[2*i + 1]\n",
    "                orig = input_shape[-(i+1)]\n",
    "                new_sz = orig + left + right\n",
    "                new_sizes.append(new_sz)\n",
    "                reps.append(np.ceil(new_sz / orig))\n",
    "\n",
    "            # repeat_sizes는 앞쪽 차원까지 고려\n",
    "            front_shape_len = x.ndim - dim\n",
    "            repeat_sizes = [1] * front_shape_len + reps[::-1]\n",
    "            x_rep = x.repeat(*repeat_sizes)\n",
    "\n",
    "            # 가운데 영역 slicing\n",
    "            slices = []\n",
    "            for i in range(dim):\n",
    "                orig = input_shape[-(i+1)]\n",
    "                new_sz = new_sizes[i]\n",
    "                rep_count = reps[i]\n",
    "                start = (rep_count * orig - new_sz) // 2\n",
    "                slices.append(slice(start, start + new_sz))\n",
    "            slices = slices[::-1]\n",
    "\n",
    "            out_slices = (Ellipsis,) + tuple(slices)\n",
    "            return x_rep[out_slices]\n",
    "        else:\n",
    "            # circular 아닌 경우\n",
    "            input_shape = x.shape[-dim:]\n",
    "            pad_pairs = [(pad[2*i], pad[2*i+1]) for i in range(dim)]\n",
    "            pad_pairs = pad_pairs[::-1]\n",
    "\n",
    "            for i, (left, right) in enumerate(pad_pairs):\n",
    "                cur_left, cur_right = left, right\n",
    "                current_dim_size = x.shape[-(i+1)]\n",
    "\n",
    "                if mode == 'reflect':\n",
    "                    max_once = current_dim_size - 1\n",
    "                elif mode == 'replicate':\n",
    "                    max_once = current_dim_size\n",
    "                else:\n",
    "                    max_once = current_dim_size\n",
    "\n",
    "                while cur_left > 0:\n",
    "                    this_pad = min(cur_left, max_once)\n",
    "                    pad_config = [0]*(2*dim)\n",
    "                    pad_config[2*i] = this_pad\n",
    "                    if mode == 'constant':\n",
    "                        x = F.pad(x, pad_config, mode=mode, value=value)\n",
    "                    else:\n",
    "                        x = F.pad(x, pad_config, mode=mode)\n",
    "                    cur_left -= this_pad\n",
    "\n",
    "                while cur_right > 0:\n",
    "                    this_pad = min(cur_right, max_once)\n",
    "                    pad_config = [0]*(2*dim)\n",
    "                    pad_config[2*i + 1] = this_pad\n",
    "                    if mode == 'constant':\n",
    "                        x = F.pad(x, pad_config, mode=mode, value=value)\n",
    "                    else:\n",
    "                        x = F.pad(x, pad_config, mode=mode)\n",
    "                    cur_right -= this_pad\n",
    "\n",
    "            return x\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, output_shape:Optional[tuple]=None) -> torch.Tensor:\n",
    "        \n",
    "        if output_shape is not None and tuple(x.shape[-len(output_shape):]) != tuple(output_shape): \n",
    "            pad = self.calc_pad(x.shape, output_shape)\n",
    "            if isinstance(self.padding_mode, str):\n",
    "                mode = self.padding_mode\n",
    "                x = self.pad(x, pad, mode=mode)\n",
    "            else:\n",
    "                for i, p in enumerate(pad):\n",
    "                    mode = self.padding_mode[i]\n",
    "                    x = self.pad(x, (p if j in [2*i, 2*i + 1] else 0 for j in range(len(pad))), mode=mode)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "# class SpectralConv(BaseSpectralConv):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.norm = self.fft_norm\n",
    "\n",
    "#     def forward(\n",
    "#         self, x: torch.Tensor, output_shape: Optional[Tuple[int]] = None\n",
    "#     ):\n",
    "#         batch_size, channels, *data_shape = x.shape\n",
    "#         fft_shape = list(data_shape) \n",
    "#         if not self.complex_data: fft_shape[-1] = fft_shape[-1] // 2 + 1 \n",
    "#         fft_dims = list(range(-len(data_shape), 0))\n",
    "#         shift_dims = fft_dims\n",
    "#         if not self.complex_data: shift_dims = fft_dims[:-1]\n",
    "\n",
    "#         mode_sizes = output_shape if output_shape is not None else data_shape\n",
    "\n",
    "#         ## FNO integral kernel computation\n",
    "#         if self.fno_block_precision == \"half\": x = x.half()\n",
    "#         x = self.fft(x, dim=fft_dims)\n",
    "#         x = self.fftshift(x, dim=shift_dims)\n",
    "#         if self.fno_block_precision == \"mixed\": x = x.chalf()\n",
    "\n",
    "#         x_fno = torch.zeros([batch_size, self.out_channels, *fft_shape],\n",
    "#                               device=x.device, \n",
    "#                               dtype=torch.chalf if self.fno_block_precision in [\"half\", \"mixed\"] else torch.cfloat\n",
    "#                               )\n",
    "#         slices_w = self.calc_slice_w(self.n_modes, self.max_n_modes, fft_shape, self.separable)\n",
    "#         weight = self.weight[slices_w]\n",
    "#         slices_x = self.calc_slices_x(fft_shape, weight.shape, self.separable)\n",
    "#         x_fno[slices_x] = self._contract(x[slices_x], weight, separable=self.separable)\n",
    "\n",
    "#         x_fno = self.zero_padding(x_fno, mode_sizes, self.complex_data)\n",
    "#         x_fno = self.fftshift(x_fno, dim=shift_dims)\n",
    "#         x = self.ifft(x_fno, dim=fft_dims)\n",
    "\n",
    "#         if self.bias is not None: x = x + self.bias\n",
    "#         return x\n",
    "\n",
    "#     def calc_slice_w(self, n_modes, max_n_modes, fft_size, separable:bool=False):\n",
    "#         # if current modes are less than max, start indexing modes closer to the center of the weight tensor\n",
    "#         starts = [(max_modes - min(size, n_mode)) for (size, n_mode, max_modes) in zip(fft_size, n_modes, max_n_modes)]\n",
    "#         # if contraction is separable, weights have shape (channels, modes_x, ...)\n",
    "#         # otherwise they have shape (in_channels, out_channels, modes_x, ...)\n",
    "#         if separable: \n",
    "#             slices_w = [slice(None)] # channels\n",
    "#         else:\n",
    "#             slices_w =  [slice(None), slice(None)] # in_channels, out_channels\n",
    "#         if self.complex_data:\n",
    "#             slices_w += [slice(start//2, -start//2) if start else slice(start, None) for start in starts]\n",
    "#         else:\n",
    "#             # The last mode already has redundant half removed in real FFT\n",
    "#             slices_w += [slice(start//2, -start//2) if start else slice(start, None) for start in starts[:-1]]\n",
    "#             slices_w += [slice(None, -starts[-1]) if starts[-1] else slice(None)]\n",
    "#         return slices_w\n",
    "\n",
    "#     def calc_slices_x(self, fft_size, weight_shape, separable:bool=False):\n",
    "#         # if separable conv, weight tensor only has one channel dim\n",
    "#         if separable:\n",
    "#             weight_start_idx = 1\n",
    "#         # otherwise drop first two dims (in_channels, out_channels)\n",
    "#         else:\n",
    "#             weight_start_idx = 2\n",
    "        \n",
    "#         slices_x =  [slice(None), slice(None)] # Batch_size, channels\n",
    "\n",
    "#         for all_modes, kept_modes in zip(fft_size, list(weight_shape[weight_start_idx:])):\n",
    "#             # After fft-shift, the 0th frequency is located at n // 2 in each direction\n",
    "#             # We select n_modes modes around the 0th frequency (kept at index n//2) by grabbing indices\n",
    "#             # n//2 - n_modes//2  to  n//2 + n_modes//2       if n_modes is even\n",
    "#             # n//2 - n_modes//2  to  n//2 + n_modes//2 + 1   if n_modes is odd\n",
    "#             center = all_modes // 2\n",
    "#             negative_freqs = kept_modes // 2\n",
    "#             positive_freqs = kept_modes // 2  + kept_modes % 2\n",
    "\n",
    "#             # this slice represents the desired indices along each dim\n",
    "#             slices_x += [slice(center - negative_freqs, center + positive_freqs)]\n",
    "        \n",
    "#         if weight_shape[-1] < fft_size[-1]:\n",
    "#             slices_x[-1] = slice(None, weight_shape[-1])\n",
    "#         else:\n",
    "#             slices_x[-1] = slice(None)\n",
    "#         return slices_x\n",
    "\n",
    "#     def zero_padding(self, Fx: torch.Tensor, mode_size: tuple, complex_data: bool=False):\n",
    "#         in_shape = list(Fx.shape[-len(mode_size):])\n",
    "#         mode_size = list(mode_size)\n",
    "#         if in_shape == mode_size: return Fx\n",
    "#         if not complex_data: mode_size[-1] = mode_size[-1] // 2 + 1\n",
    "\n",
    "#         pad_list = []\n",
    "#         for i, (in_dim, out_dim) in enumerate(zip(reversed(in_shape), reversed(mode_size))):\n",
    "#             diff = out_dim - in_dim # max(out_dim - in_dim, 0)\n",
    "#             left = 0 if not complex_data and i == 0 else diff // 2\n",
    "#             right = diff - left\n",
    "#             pad_list.extend([left, right])\n",
    "\n",
    "#         # Apply pad: F.pad expects pads from last to first dimension\n",
    "#         if any(diff > 0 for diff in (t - i for t, i in zip(mode_size, in_shape))):\n",
    "#             Fx = F.pad(Fx, pad_list, mode=\"constant\", value=0)\n",
    "#         return Fx\n",
    "    \n",
    "#     def fft(self, x: torch.Tensor, dim=None, norm=None, complex_data: bool=None) -> torch.Tensor:\n",
    "#         if dim is None: dim = tuple(range(-x.ndim, 0))\n",
    "#         if norm is None: norm = self.norm\n",
    "#         if complex_data is None: complex_data = self.complex_data\n",
    "\n",
    "#         if complex_data:\n",
    "#             Fx = torch.fft.fftn(x, dim=dim, norm=norm)\n",
    "#         else:\n",
    "#             Fx = torch.fft.rfftn(x, dim=dim, norm=norm)\n",
    "#         return Fx\n",
    "    \n",
    "#     def ifft(self, x: torch.Tensor, dim=None, norm=None, complex_data: bool=None) -> torch.Tensor:\n",
    "#         if dim is None: dim = tuple(range(-x.ndim, 0))\n",
    "#         if norm is None: norm = self.norm\n",
    "#         if complex_data is None: complex_data = self.complex_data\n",
    "\n",
    "#         if complex_data:\n",
    "#             Fx = torch.fft.ifftn(x, dim=dim, norm=norm)\n",
    "#         else:\n",
    "#             Fx = torch.fft.irfftn(x, dim=dim, norm=norm)\n",
    "#         return Fx\n",
    "    \n",
    "#     def fftshift(self, x: torch.Tensor, dim=None) -> torch.Tensor:\n",
    "#         if dim is None: dim = tuple(range(-x.ndim, 0))\n",
    "#         if len(dim) > 1: return torch.fft.fftshift(x, dim=dim)\n",
    "#         else: return x\n",
    "\n",
    "class SpectralConv(BaseSpectralConv):\n",
    "    \"\"\"\n",
    "    SpectralConv module with CNN skip connection and normalization options.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, output_shape: Optional[Tuple[int]] = None\n",
    "    ):\n",
    "        \"\"\"Generic forward pass for the Factorized Spectral Conv\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            input activation of size (batch_size, channels, d1, ..., dN)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensorized_spectral_conv(x)\n",
    "        \"\"\"\n",
    "        batchsize, channels, *mode_sizes = x.shape\n",
    "\n",
    "        fft_size = list(mode_sizes)\n",
    "        if not self.complex_data:\n",
    "            fft_size[-1] = fft_size[-1] // 2 + 1  # Redundant last coefficient in real spatial data\n",
    "        fft_dims = list(range(-self.order, 0))\n",
    "\n",
    "        \n",
    "        if self.resolution_scaling_factor is not None and output_shape is None:\n",
    "            mode_sizes = tuple([round(s * r) for (s, r) in zip(mode_sizes, self.resolution_scaling_factor)])\n",
    "\n",
    "        if output_shape is not None:\n",
    "            mode_sizes = output_shape\n",
    "\n",
    "        if self.fno_block_precision == \"half\":\n",
    "            x = x.half()\n",
    "        def zero_padding(Fx: torch.Tensor, mode_size: tuple, complex_data: bool=False):\n",
    "            in_shape = list(Fx.shape[-len(mode_size):])\n",
    "            mode_size = list(mode_size)\n",
    "            if in_shape == mode_size: return Fx\n",
    "            if not complex_data: mode_size[-1] = mode_size[-1] // 2 + 1\n",
    "\n",
    "            pad_list = []\n",
    "            for i, (in_dim, out_dim) in enumerate(zip(reversed(in_shape), reversed(mode_size))):\n",
    "                diff = out_dim - in_dim # max(out_dim - in_dim, 0)\n",
    "                left = 0 if not complex_data and i == 0 else diff // 2\n",
    "                right = diff - left\n",
    "                pad_list.extend([left, right])\n",
    "\n",
    "            # Apply pad: F.pad expects pads from last to first dimension\n",
    "            if any(diff > 0 for diff in (t - i for t, i in zip(mode_size, in_shape))):\n",
    "                Fx = F.pad(Fx, pad_list, mode=\"constant\", value=0)\n",
    "            return Fx\n",
    "\n",
    "\n",
    "        if self.complex_data:\n",
    "            x = torch.fft.fftn(x, norm=self.fft_norm, dim=fft_dims)\n",
    "            dims_to_fft_shift = fft_dims\n",
    "        else: \n",
    "            x = torch.fft.rfftn(x, norm=self.fft_norm, dim=fft_dims)\n",
    "            # When x is real in spatial domain, the last half of the last dim is redundant.\n",
    "            # See :ref:`fft_shift_explanation` for discussion of the FFT shift.\n",
    "            dims_to_fft_shift = fft_dims[:-1] \n",
    "        \n",
    "        \n",
    "        def calc_slice_w(n_modes, max_n_modes, fft_size, separable:bool=False):\n",
    "            # if current modes are less than max, start indexing modes closer to the center of the weight tensor\n",
    "            starts = [(max_modes - min(size, n_mode)) for (size, n_mode, max_modes) in zip(fft_size, n_modes, max_n_modes)]\n",
    "            # if contraction is separable, weights have shape (channels, modes_x, ...)\n",
    "            # otherwise they have shape (in_channels, out_channels, modes_x, ...)\n",
    "            if separable: \n",
    "                slices_w = [slice(None)] # channels\n",
    "            else:\n",
    "                slices_w =  [slice(None), slice(None)] # in_channels, out_channels\n",
    "            if self.complex_data:\n",
    "                slices_w += [slice(start//2, -start//2) if start else slice(start, None) for start in starts]\n",
    "            else:\n",
    "                # The last mode already has redundant half removed in real FFT\n",
    "                slices_w += [slice(start//2, -start//2) if start else slice(start, None) for start in starts[:-1]]\n",
    "                slices_w += [slice(None, -starts[-1]) if starts[-1] else slice(None)]\n",
    "            return slices_w\n",
    "\n",
    "        def calc_slices_x(fft_size, weight_shape, separable:bool=False):\n",
    "            # if separable conv, weight tensor only has one channel dim\n",
    "            if separable:\n",
    "                weight_start_idx = 1\n",
    "            # otherwise drop first two dims (in_channels, out_channels)\n",
    "            else:\n",
    "                weight_start_idx = 2\n",
    "            \n",
    "            slices_x =  [slice(None), slice(None)] # Batch_size, channels\n",
    "\n",
    "            for all_modes, kept_modes in zip(fft_size, list(weight_shape[weight_start_idx:])):\n",
    "                # After fft-shift, the 0th frequency is located at n // 2 in each direction\n",
    "                # We select n_modes modes around the 0th frequency (kept at index n//2) by grabbing indices\n",
    "                # n//2 - n_modes//2  to  n//2 + n_modes//2       if n_modes is even\n",
    "                # n//2 - n_modes//2  to  n//2 + n_modes//2 + 1   if n_modes is odd\n",
    "                center = all_modes // 2\n",
    "                negative_freqs = kept_modes // 2\n",
    "                positive_freqs = kept_modes // 2  + kept_modes % 2\n",
    "\n",
    "                # this slice represents the desired indices along each dim\n",
    "                slices_x += [slice(center - negative_freqs, center + positive_freqs)]\n",
    "            \n",
    "            if weight_shape[-1] < fft_size[-1]:\n",
    "                slices_x[-1] = slice(None, weight_shape[-1])\n",
    "            else:\n",
    "                slices_x[-1] = slice(None)\n",
    "            return slices_x\n",
    "        ### fno layer\n",
    "        if self.order > 1:\n",
    "            x = torch.fft.fftshift(x, dim=dims_to_fft_shift)\n",
    "\n",
    "        if self.fno_block_precision == \"mixed\":\n",
    "            # if 'mixed', the above fft runs in full precision, but the\n",
    "            # following operations run at half precision\n",
    "            x = x.chalf()\n",
    "            \n",
    "\n",
    "        if self.fno_block_precision in [\"half\", \"mixed\"]:\n",
    "            out_dtype = torch.chalf\n",
    "        else:\n",
    "            out_dtype = torch.cfloat\n",
    "        out_fft = torch.zeros([batchsize, self.out_channels, *fft_size],\n",
    "                              device=x.device, dtype=out_dtype)\n",
    "        \n",
    "        slices_w = calc_slice_w(self.n_modes, self.max_n_modes, fft_size, self.separable)\n",
    "        weight = self.weight[slices_w]\n",
    "        slices_x = calc_slices_x(fft_size, weight.shape, self.separable)\n",
    "        out_fft[slices_x] = self._contract(x[slices_x], weight, separable=self.separable)\n",
    "\n",
    "        out_fft = zero_padding(out_fft, mode_sizes, self.complex_data)\n",
    "\n",
    "        \n",
    "        if self.order > 1:\n",
    "            out_fft = torch.fft.fftshift(out_fft, dim=dims_to_fft_shift)\n",
    "        if self.complex_data:\n",
    "            x = torch.fft.ifftn(out_fft, dim=fft_dims, norm=self.fft_norm) # x = torch.fft.ifftn(x_fft, dim=fft_dims, norm=self.fft_norm).real\n",
    "        else:\n",
    "            x = torch.fft.irfftn(out_fft, dim=fft_dims, norm=self.fft_norm)\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNOBlocks(BaseFNOBlocks):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.frozen_layer = []\n",
    "\n",
    "        self.cnn_hidden_channels = int(self.out_channels * 1)\n",
    "        self.cnn_n_layer = 2\n",
    "        cnn_skip = nn.ModuleList()\n",
    "        cnn1x1 = nn.ModuleList()\n",
    "        for _ in range(self.n_layers):\n",
    "            cnn_layer = nn.ModuleList()\n",
    "            for i in range(self.cnn_n_layer):\n",
    "                cnn_layer.append(WTConv2d(self.in_channels if i == 0 else self.cnn_hidden_channels, \n",
    "                                          self.cnn_hidden_channels, kernel_size=3, stride=1, bias=False, wt_levels=2, wt_type='db2'))\n",
    "                # cnn_layer.append(CustomConv2d(self.in_channels if i == 0 else self.cnn_hidden_channels, \n",
    "                #                               self.cnn_hidden_channels, kernel_size=3, stride=1, padding=1, padding_mode='circular'))\n",
    "                cnn_layer.append(nn.InstanceNorm2d(self.cnn_hidden_channels))\n",
    "                cnn_layer.append(nn.GELU())\n",
    "            cnn_layer = nn.Sequential(*cnn_layer)\n",
    "            cnn_skip.append(cnn_layer)\n",
    "\n",
    "            cnn1x1.append(nn.Sequential(nn.Conv2d(\n",
    "                self.out_channels + self.cnn_hidden_channels, # + self.in_channels,\n",
    "                self.out_channels, kernel_size=1, \n",
    "            )))\n",
    "        self.cnn_skip = nn.ModuleList(cnn_skip)\n",
    "        self.cnn1x1 = nn.ModuleList(cnn1x1)\n",
    "    \n",
    "    def forward(self, x, index=0, output_shape=None, positional_encoder=None):\n",
    "        if positional_encoder is not None: x = positional_encoder(x)\n",
    "        if not 'fno' in self.frozen_layer: \n",
    "            x_fno = self.convs[index](x, output_shape=output_shape)\n",
    "            if self.norm is not None: x_fno = self.norm[self.n_norms * index](x_fno)\n",
    "            # x_fno += x\n",
    "            if hook: hook(x_fno, 'x_fno')\n",
    "        if not 'cnn' in self.frozen_layer: \n",
    "              \n",
    "            # x = self.low_pass_filter(x)\n",
    "            if hook: hook(x, 'hpf(x)')\n",
    "            x_cnn = self.cnn_skip[index](x)\n",
    "            # if hook: hook(x_cnn, 'cnn(hpf(x))')\n",
    "            # x_cnn = self.low_pass_filter(x_cnn)\n",
    "            # if hook: hook(x_cnn, 'hpf(cnn(hpf(x)))')\n",
    "            \n",
    "            if hook: hook(x_cnn, 'x_cnn')\n",
    "            # x = x_fno + x_cnn\n",
    "            # x_cnn = x * x_cnn\n",
    "            x = torch.concat([x_fno, x_cnn], dim=1) # x = x_fno\n",
    "            # x = torch.concat([x_fno, x_fno * x_cnn, x_cnn, x], dim=1)\n",
    "            # x = x_fno + x * x_cnn\n",
    "            if hook: hook(x, 'x_fno + x_cnn')\n",
    "            \n",
    "            x = self.non_linearity(x)\n",
    "            if hook: hook(x, 'non_linearity')\n",
    "            x = self.cnn1x1[index](x)\n",
    "            if hook: hook(x, 'act')\n",
    "            # x += x_fno\n",
    "        else: \n",
    "            x = x_fno\n",
    "        if positional_encoder is not None: x = positional_encoder(x)\n",
    "        return x\n",
    "    \n",
    "    def low_pass_filter(self, x):\n",
    "            def calc_slices_x(fft_size, n_modes, max_n_modes, complex_data=False):\n",
    "                \"\"\"\n",
    "                Return a list of slice objects for indexing the input x (after FFT) \n",
    "                to select only the required modes in each axis.\n",
    "\n",
    "                Parameters:\n",
    "                    fft_size (tuple): FFT size along each dimension.\n",
    "                    n_modes (tuple): Number of modes to keep along each dimension.\n",
    "                    max_n_modes (tuple): Maximum available modes along each dimension.\n",
    "                    complex_data (bool): Whether input is complex (True) or real (False).\n",
    "\n",
    "                Returns:\n",
    "                    slices_x (list of slice): Slices for indexing x to select wanted modes.\n",
    "                \"\"\"\n",
    "                # Compute starting indices for each dimension\n",
    "                starts = [(max_modes - min(size, n_mode)) for (size, n_mode, max_modes) in zip(fft_size, n_modes, max_n_modes)]\n",
    "\n",
    "                # Always slice batch and channel as full\n",
    "                slices_x = [slice(None), slice(None)]\n",
    "\n",
    "                # For each dimension, select the center region (kept modes)\n",
    "                for dim, (size, n_mode, start) in enumerate(zip(fft_size, n_modes, starts)):\n",
    "                    # Center index after fftshift\n",
    "                    center = size // 2\n",
    "                    kept_modes = min(size, n_mode)\n",
    "                    neg_freqs = kept_modes // 2\n",
    "                    pos_freqs = kept_modes // 2 + kept_modes % 2\n",
    "\n",
    "                    # Final slice for this dimension\n",
    "                    slices_x.append(slice(center - neg_freqs, center + pos_freqs))\n",
    "\n",
    "                # If real input, last FFT axis is special (half spectrum is redundant)\n",
    "                if not complex_data:\n",
    "                    # For real FFT, only positive frequencies along the last axis are kept\n",
    "                    last_dim = len(fft_size) + 1  # +2 for batch, channel; -1 for zero-indexing\n",
    "                    last_mode = n_modes[-1]\n",
    "                    slices_x[-1] = slice(0, last_mode)\n",
    "\n",
    "                return slices_x \n",
    "            \n",
    "            Fx = torch.fft.fftn(x, dim=(-2, -1), norm='forward')\n",
    "            Fx = torch.fft.fftshift(Fx, dim=(-2, -1))\n",
    "            idx = calc_slices_x(list(Fx.shape[2:]), n_modes=self.n_modes, max_n_modes=self.n_modes, complex_data=True)\n",
    "            Fx[idx] = 0. + 0j\n",
    "            Fx = torch.fft.fftshift(Fx, dim=(-2, -1))\n",
    "            x = torch.fft.ifftn(Fx, dim=(-2, -1), norm='forward').real\n",
    "            return x\n",
    "    \n",
    "class FNO(BaseFNO):\n",
    "    def __init__(self, \n",
    "        non_linearity: callable = nn.GELU(), # CNO_activation(activation=F.gelu), Dealiasing_activation(activation=F.gelu), #         \n",
    "        *args, **kwargs):\n",
    "        super().__init__(conv_module=SpectralConv, non_linearity=non_linearity, *args, **kwargs)\n",
    "        kwargs.pop('in_channels', None)\n",
    "        kwargs.pop('out_channels', None)\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            in_channels=self.hidden_channels, \n",
    "            out_channels=self.hidden_channels,\n",
    "            conv_module=SpectralConv, \n",
    "            non_linearity=non_linearity,\n",
    "            *args, **kwargs\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.projection = ChannelMLP(\n",
    "            in_channels=self.hidden_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            hidden_channels=self.projection_channels,\n",
    "            n_layers=4,\n",
    "            n_dim=self.n_dim,\n",
    "            non_linearity=non_linearity,\n",
    "        )\n",
    "        if self.complex_data:\n",
    "            self.projection = ComplexValued(self.projection)\n",
    "\n",
    "        self.positional_encoder = RoPE(out_channels=self.hidden_channels, rope_theta=10.0, isproj=False, )\n",
    "        self.frozen_layer = []\n",
    "    \n",
    "    # def forward(self, x_branch: torch.Tensor, x_trunk: torch.Tensor, *args, **kwargs):\n",
    "    def forward(self, x, output_shape=None, *args, **kwargs):\n",
    "        # self.frozen_layer = ['fno']\n",
    "        if output_shape is None:\n",
    "            output_shape = [None]*self.n_layers\n",
    "        elif isinstance(output_shape, tuple):\n",
    "            output_shape = [None]*(self.n_layers - 1) + [output_shape]\n",
    "\n",
    "        if hook: hook(x, 'input')\n",
    "        if not 'ae' in self.frozen_layer: \n",
    "            x = self.lifting(x)     # (batch_size, output_dim)\n",
    "            if hook: hook(x, 'lifting')\n",
    "        if False: \n",
    "            x = self.positional_encoder(x)\n",
    "            # x *= pe.to(x.device)\n",
    "            if hook: hook(x, 'x + pe')\n",
    "\n",
    "        if not 'fno' in self.frozen_layer: \n",
    "            for layer_idx in range(self.n_layers):\n",
    "                if hook: hook.set_prefix(f'FNO Layer {layer_idx}')\n",
    "                x = self.fno_blocks(x, layer_idx, output_shape=output_shape[layer_idx], \n",
    "                                    # positional_encoder=self.positional_encoder\n",
    "                                    )\n",
    "\n",
    "                # x *= pe.to(x.device)\n",
    "            if hook: hook.set_prefix('')\n",
    "            \n",
    "        # Element-wise multiplication and summation over the output dimension\n",
    "        if False:\n",
    "            pos_embedding = self._positional_embedding(x)\n",
    "            x_branch = self.lifting_branch(pos_embedding)  # (batch_size, output_dim)\n",
    "            x_branch *= pe.to(x_branch.device)\n",
    "            x = x_branch * x  # (batch_size, 1  )   \n",
    "            if hook: hook(x, 'x + x_branch')\n",
    "        if not 'ae' in self.frozen_layer: \n",
    "            x = self.projection(x)\n",
    "            if hook: hook(x, 'projection')\n",
    "        return x\n",
    "    \n",
    "    def freeze_layers(self, layer:Literal['AE', 'fno', 'cnn', 'all']):\n",
    "        \"\"\"\n",
    "        Freeze specific layers of the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : Literal['AE', 'fno', 'cnn', 'all']\n",
    "            The layer(s) to freeze.\n",
    "        \"\"\"\n",
    "        if layer == 'AE':\n",
    "            for param in self.lifting.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.projection.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif layer == 'fno':\n",
    "            for param in self.fno_blocks.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif layer == 'cnn':\n",
    "            for block in self.fno_blocks.convs:\n",
    "                if isinstance(block.cnn_skip, ScaledCNNLayer):\n",
    "                    for param in block.cnn_skip.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    block.cnn1x1.requires_grad = False\n",
    "                    \n",
    "        elif layer == 'all':\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown layer type: {layer}\")\n",
    "    \n",
    "    def unfreeze_layers(self):\n",
    "        \"\"\"\n",
    "        Unfreeze all layers of the model.\n",
    "        \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_optimizer \n",
    "from utils.refer.soap import SOAP\n",
    "\n",
    "SCHEDULERS = {\n",
    "    'StepLR': lambda optimizer, **params: torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, **(params | {'step_size': 10, 'gamma': 0.1})\n",
    "    ),\n",
    "    'ExponentialLR': lambda optimizer, **params: torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, **(params | {'gamma': 0.95})\n",
    "    ),\n",
    "    'MultiStepLR': lambda optimizer, **params: torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, **(params | {'milestones': [30, 80], 'gamma': 0.1})\n",
    "    ),\n",
    "    'CosineAnnealingLR': lambda optimizer, **params: torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, **(params | {'T_max': 10})\n",
    "    ),\n",
    "    'CosineAnnealingWarmRestarts': lambda optimizer, **params: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, **(params | {'T_0': 10, 'T_mult': 2})\n",
    "    ),\n",
    "    'OneCycleLR': lambda optimizer, **params: torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, **(params | {'max_lr': 0.1, 'total_steps': 100})\n",
    "    ),\n",
    "    'ReduceLROnPlateau': lambda optimizer, **params: torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, **(params | {'mode': 'min', 'factor': 0.1, 'patience': 10})\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "OPTIMIZERS = {\n",
    "    'SGD': lambda model, **params: torch.optim.SGD(\n",
    "        model, **({'lr': 0.01, 'momentum': 0.9} | params)\n",
    "    ),\n",
    "    'Adam': lambda model, **params: torch.optim.Adam(\n",
    "        model, **({'lr': 1e-3, 'betas': (0.9, 0.999)} | params)\n",
    "    ),\n",
    "    'AdamW': lambda model, **params: torch.optim.AdamW(\n",
    "        model, **({'lr': 1e-3, 'weight_decay': 1e-2} | params)\n",
    "    ),\n",
    "    'RMSprop': lambda model, **params: torch.optim.RMSprop(\n",
    "        model, **({'lr': 1e-2, 'alpha': 0.99, 'momentum': 0.9} | params)\n",
    "    ),\n",
    "    'Adagrad': lambda model, **params: torch.optim.Adagrad(\n",
    "        model, **({'lr': 1e-2} | params)\n",
    "    ),\n",
    "    'Adadelta': lambda model, **params: torch.optim.Adadelta(\n",
    "        model, **({'lr': 1.0, 'rho': 0.9} | params)\n",
    "    ),\n",
    "    'Adamax': lambda model, **params: torch.optim.Adamax(\n",
    "        model, **({'lr': 2e-3} | params)\n",
    "    ),\n",
    "    'NAdam': lambda model, **params: torch.optim.NAdam(\n",
    "        model, **({'lr': 2e-3, 'betas': (0.9, 0.999)} | params)\n",
    "    ),\n",
    "    'Shampoo': (\n",
    "        (lambda model, **params: torch_optimizer.Shampoo(\n",
    "            model, **({'lr': 1e-3, 'momentum': 0.9, 'weight_decay': 0.0} | params)\n",
    "        )) \n",
    "    ),\n",
    "    'SOAP': (\n",
    "        (lambda model, **params: SOAP(\n",
    "            model, **({'lr': 1e-3,} | params)\n",
    "        )) \n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class CustomModule(nn.Module):\n",
    "    def __init__(self, \n",
    "                 model:Optional[callable]= None,\n",
    "                 modelconfig:Optional[dict]=None, \n",
    "                 optconfig:Optional[dict]=None, \n",
    "                 \n",
    "                 loss_fn: Optional[callable] = nn.MSELoss(),\n",
    "                 transformer:Optional[callable]=None, \n",
    "                 **kwargs, \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.modelconfig = modelconfig\n",
    "        self.optconfig = optconfig\n",
    "        self.hparams = kwargs\n",
    "        self.device = device\n",
    "\n",
    "        self.model = self.build_model() if model is None else model.to(device)\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "        if optconfig is not None: self.configure_optimizers()\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "        self.transformer = transformer\n",
    "\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model = FNO(**self.modelconfig['params'],).to(self.device)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer is not None: \n",
    "            return self.optimizer, self.scheduler\n",
    "        self.optimizer = OPTIMIZERS[self.optconfig['name']](\n",
    "            self.model.parameters(), \n",
    "            **self.optconfig['params']\n",
    "        )\n",
    "\n",
    "        self.scheduler = None\n",
    "        if self.optconfig['scheduler']: \n",
    "            self.scheduler = SCHEDULERS[self.optconfig['scheduler']['name']](\n",
    "                self.optimizer, \n",
    "                **self.optconfig['scheduler'].get('params', {}),\n",
    "                ) \n",
    "        return self.optimizer, self.scheduler\n",
    "    \n",
    "    def forward(self, data, output_shape=None):\n",
    "        return self.model(data.to(self.device), output_shape=output_shape)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, ret_log:bool=False):\n",
    "        if self.transformer: batch = self.transformer(batch)\n",
    "        data, target = batch\n",
    "        \n",
    "        # data = data[:, 0]\n",
    "        # target = target[:, 0]\n",
    "        if hook and batch_idx % hook.hook_every_n_iter == 0: hook.open_hook()\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.forward(data.to(self.device), output_shape=target.shape[2:])\n",
    "        loss = self.loss_fn(output, target.to(self.device))\n",
    "        loss.backward()\n",
    "        if hook and batch_idx % hook.hook_every_n_iter == 0: \n",
    "            hook.close_hook(fname='./result/' + f'Training iter{batch_idx}')\n",
    "            hook.step()\n",
    "\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0: self.epoch += 1\n",
    "        self.log('loss', loss.item(), on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx, ret_log:bool=True):\n",
    "        if self.transformer: batch = self.transformer(batch)\n",
    "        data, target = batch\n",
    "\n",
    "        # data = data[:, 0]\n",
    "        # target = target[:, 0]\n",
    "        if hook and batch_idx == 0: hook.open_hook()\n",
    "        output = self.forward(data.to(self.device), output_shape=target.shape[2:])\n",
    "        loss = self.loss_fn(output, target.to(self.device))\n",
    "        if hook and batch_idx == 0: hook.close_hook(fname='./result/' + f'Valid iter{hook.iteration}_n{target.shape[-1]}-n{target.shape[-1]}')\n",
    "\n",
    "        self.log('val_loss', loss.item(), on_step=False)\n",
    "        if ret_log: \n",
    "            log = {}\n",
    "            log.update({\"loss\": loss.item(), \"output\": output[:].detach().cpu(), 'batch': [data, target.detach().cpu()]})\n",
    "            return log\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test_step(self, batch, batch_idx, ret_log:bool=True):\n",
    "        if self.transformer: batch = self.transformer(batch)\n",
    "        \n",
    "        data, target = batch\n",
    "\n",
    "        # data = data[:, 0]\n",
    "        # target = target[:, 0]\n",
    "\n",
    "        output = self.forward(data.to(self.device), output_shape=target.shape[2:])\n",
    "\n",
    "        if ret_log: \n",
    "            log = {}\n",
    "            log.update({# \"loss\": loss.item(), \n",
    "                        \"output\": output[:].detach().cpu(), 'batch': [data.detach().cpu(), target.detach().cpu()]})\n",
    "            return log\n",
    "        return output\n",
    "\n",
    "    def save(self, path, checkpoint:dict={}):\n",
    "        checkpoint['model_state_dict'] = self.model.state_dict()\n",
    "        checkpoint['optimizer_state_dict'] = self.optimizer.state_dict()\n",
    "        if self.scheduler: checkpoint[f'scheduler'] = self.scheduler.state_dict()\n",
    "\n",
    "        torch.save(checkpoint, path + '.pth')\n",
    "\n",
    "    def load(self,\n",
    "        path, \n",
    "        verbose=True, \n",
    "        load_opt:bool=True,\n",
    "        freeze:bool=False,\n",
    "        ):\n",
    "        if os.path.exists(path + '.pth') and os.path.getsize(path + '.pth'):\n",
    "            checkpoint = torch.load(path + '.pth', weights_only=False)\n",
    "\n",
    "            self.model.load_state_dict(\n",
    "                checkpoint['model_state_dict'], \n",
    "                strict=False,\n",
    "                )\n",
    "            if freeze: \n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if name in checkpoint['model_state_dict']:\n",
    "                        param.requires_grad = False\n",
    "            if verbose: print(f'model loaded from {path}')\n",
    "            if load_opt:\n",
    "                if self.optimizer and 'optimizer_state_dict' in checkpoint: \n",
    "                    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                    if verbose: print(f'optimizer loaded from {path}')\n",
    "                if self.scheduler and 'scheduler' in checkpoint: \n",
    "                    self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "                    if verbose: print(f'scheduler loaded from {path}')\n",
    "    \n",
    "    def log(self, name, value, prog_bar=False, logger=None, on_step=None, on_epoch=None, reduce_fx='mean', enable_graph=False, sync_dist=False, sync_dist_group=None, add_dataloader_idx=True, batch_size=None, metric_attribute=None, rank_zero_only=False):\n",
    "        commit = False if on_step is False else True\n",
    "        wandb.log({name: value}, commit=commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.BaseCallback import BaseCallback\n",
    "from utils.CFDFunction import calc_energy_spectrum, calc_pdf, calc_phase_error\n",
    "from utils.Plots import plot_2d_surface, plot_spectrum, plot_pdf\n",
    "\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, \n",
    "                 criterions, \n",
    "                 file_dir:str='', \n",
    "                 fname:str ='',\n",
    "                 device:str =None, \n",
    "                 ):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.criterions = criterions # DL criterion + CFD criterion + DL part-of-loss\n",
    "        self.file_dir = file_dir\n",
    "        self.fname = fname\n",
    "        self.device=device\n",
    "        \n",
    "    def on_validation_epoch_start(self, trainer, pl_module):\n",
    "        self.time_stamp = time.time()\n",
    "        trainer._current_val_return = {'loss': [], 'time': []}\n",
    "        for key in self.criterions.keys():\n",
    "            trainer._current_val_return[key] = []\n",
    "\n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        data, target = outputs['batch'] # batch\n",
    "        # trainer._current_val_return['batch'] = outputs['batch'] # batch\n",
    "        # trainer._current_val_return['output'] = outputs['output']\n",
    "        # trainer._current_val_return['loss'].append(outputs['loss'])\n",
    "\n",
    "        for key in self.criterions.keys():\n",
    "            value = self.criterions[key](outputs['output'].to(self.device), target.to(self.device)).item()\n",
    "\n",
    "            trainer._current_val_return[key].append(value)\n",
    "            \n",
    "        self.N = data.shape[-1]\n",
    "        if data.shape[-1] != target.shape[-1]: self.N = f'{data.shape[-1]}-{target.shape[-1]}'\n",
    "    \n",
    "    def on_validation_end(self, trainer, pl_module, fname='') -> None:\n",
    "        fname = self.fname + fname\n",
    "        # data, target = trainer._current_val_return['batch']\n",
    "        # output = trainer._current_val_return['output']\n",
    "        # if trainer.logger: trainer.logger.log({'val_loss': np.mean(trainer._current_val_return['loss'])})\n",
    "\n",
    "        epoch = trainer.current_epoch\n",
    "        print(f'  Validation Epoch: {epoch}', end='')\n",
    "        for key in self.criterions.keys():\n",
    "            value = np.mean(trainer._current_val_return[key])\n",
    "            print(f\", {key}: {value:.6f}\", end='')\n",
    "\n",
    "            if trainer.logger: trainer.logger.log({f'Val_{self.N}/epoch/'+key: value})\n",
    "        print()\n",
    "\n",
    "        plt.close('all')\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    def on_test_batch_start(self, trainer, pl_module, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        self.time_stamp = time.time()\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n",
    "        data, target = batch\n",
    "        trainer._current_test_return['batch'] = batch\n",
    "        output = trainer._current_test_return['output'] = outputs['output']\n",
    "        \n",
    "        runtime = time.time() - self.time_stamp\n",
    "        if trainer.logger: trainer.logger.log({'Test/time': runtime})\n",
    "        print(f'Test sample {batch_idx}(time: {runtime:.6f}, batch size: {len(output)})', end='')\n",
    "        for key in self.criterions.keys():\n",
    "            value = self.criterions[key](outputs['output'].to(self.device), target.to(self.device)).item()\n",
    "\n",
    "            trainer._current_test_return[key].append(value)\n",
    "            print(f\", {key}: {value:.6f}\", end='')\n",
    "        print()\n",
    "        \n",
    "        ## enstrophy spectrum\n",
    "        spectrum1 = calc_energy_spectrum(target[:,0,:], dim=(-2, -1), channel_dim=1) # np.mean([calc_enstrophy_spectrum(target[i,0,:]) for i in range(len(target))], axis=0); \n",
    "        spectrum2 = calc_energy_spectrum(output[:,0,:], dim=(-2, -1), channel_dim=1) # np.mean([calc_enstrophy_spectrum(output[i,0,:]) for i in range(len(output))], axis=0)\n",
    "        ## vorticity pdf\n",
    "        bin1, pdf1 = calc_pdf(target[:,0,:], dim=2) # np.mean([calc_pdf(target[i,0,:]) for i in range(len(target))], axis=0); \n",
    "        bin2, pdf2 = calc_pdf(output[:,0,:], dim=2) # np.mean([calc_pdf(output[i,0,:]) for i in range(len(output))], axis=0)\n",
    "\n",
    "        # ### solution field \n",
    "        plot_2d_surface(target[0,0,...,0], output[0,0,...,0], # axes=[ax1,ax2], \n",
    "                        kwargs={'figsize': (8, 4)}\n",
    "                        )\n",
    "        plt.savefig(self.file_dir + self.fname + f'_Test_sample={batch_idx}_field.png')\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        ax = fig.add_subplot(1, 2, 1)\n",
    "        plot_spectrum(spectrum1, spectrum2, ax=ax, kwargs={'title': f'enstrophy spectrum'})\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        plot_pdf(bin1, pdf1, bin2, pdf2, ax=ax, kwargs={'title': f'pdf'})\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.file_dir + self.fname + f'_Test_sample={batch_idx}_stat.png')\n",
    "        # plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        ## save .wandb\n",
    "        Nt = len(output)\n",
    "        for it in range(Nt):\n",
    "            image = np.concatenate((target[it,0,:], output[it,0,:]), axis=1)\n",
    "            if trainer.logger: trainer.logger.log({'Test/'+f'sample_{batch_idx}/'+'field': wandb.Image(image)})\n",
    "        if trainer.logger: trainer.logger.log({'Test/spectrum': wandb.plot.line_series(\n",
    "            xs=[np.arange(0, spectrum1.shape[-1]+1), np.arange(0, spectrum2.shape[-1]+1)], \n",
    "            ys = [spectrum1, spectrum2],\n",
    "            keys = ['ground truth', 'prediction'],\n",
    "            xname = ['k', 'enstrophy spectrum'],\n",
    "            title='enstrophy_spectrum', \n",
    "            )})\n",
    "        if trainer.logger: trainer.logger.log({'Test/pdf': wandb.plot.line_series(\n",
    "            xs=[bin1, bin2], \n",
    "            ys = [pdf1, pdf2],\n",
    "            keys = ['ground truth', 'prediction'],\n",
    "            xname = ['w', 'pdf'],\n",
    "            title='pdf', \n",
    "            )})\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module) -> None:\n",
    "        data, target = trainer._current_test_return['batch']\n",
    "        output = trainer._current_test_return['output']\n",
    "\n",
    "        print('Test ')\n",
    "        for key in self.criterions.keys():\n",
    "            value = np.mean(trainer._current_test_return[key])\n",
    "            print(f\", {key}: {value:.6f}\", end='')\n",
    "\n",
    "            if trainer.logger: trainer.logger.log({'Test/'+key: value})\n",
    "        print()\n",
    "\n",
    "    def preprocessing(self, x):\n",
    "        n_modes = self.n_modes\n",
    "        x = self.split(x, modes=n_modes)\n",
    "        # x = self.scaling(x, dim=2, isNormalize=False)\n",
    "        return x \n",
    "    \n",
    "    def postprocessing(self, x):\n",
    "        n_modes = self.n_modes\n",
    "        # x = self.unscaling(x)\n",
    "        x = self.unsplit(x, modes=n_modes)\n",
    "        return x\n",
    "    \n",
    "    def scaling(self, x, \n",
    "                dim=1, \n",
    "                isNormalize:bool=False):\n",
    "        dim = list(range(-dim, 0))\n",
    "        if isNormalize:\n",
    "            self.mean = x.amin(dim=dim, keepdim=True)\n",
    "            self.std = x.amax(dim=dim, keepdim=True) - self.mean\n",
    "        else: \n",
    "            self.mean = x.mean(dim=dim, keepdim=True)\n",
    "            self.std = x.std(dim=dim, keepdim=True)\n",
    "        return (x - self.mean) / self.std\n",
    "    \n",
    "    def unscaling(self, x):\n",
    "        return x * self.std + self.mean\n",
    "    \n",
    "    def split(self, x, \n",
    "              modes=None\n",
    "              ):\n",
    "\n",
    "        b, c, *data_shape = x.shape\n",
    "        fft_dims = list(range(-len(data_shape), 0))\n",
    "        Fx = torch.fft.fft2(x, dim=fft_dims, norm='forward')\n",
    "        Fx_ = torch.zeros((len(modes), b, c, *data_shape), dtype=Fx.dtype, device=x.device)\n",
    "        \n",
    "        k = [torch.fft.fftfreq(n, d=1./n) for n in data_shape]\n",
    "        # k += [torch.fft.rfftfreq(data_shape[-1], d=1./data_shape[-1])] if Fx.dtype in [torch.float16, torch.float32, torch.float64] else [torch.fft.fftfreq(data_shape[-1], d=1./data_shape[-1])]\n",
    "\n",
    "\n",
    "        k = torch.meshgrid(k, indexing='ij')\n",
    "        k = torch.stack(k)\n",
    "        k = torch.sqrt(torch.sum(k**2, axis=0)).to(x.device)\n",
    "        for i in range(len(modes)):\n",
    "            k1, k2 = modes[i]\n",
    "            idx = (k1 <= k) & (k <= k2)\n",
    "            Fx_[i] = Fx * idx\n",
    "\n",
    "        x_ = torch.fft.ifft2(Fx_, dim=fft_dims, norm='forward').real # x_ = Fx_ # # \n",
    "        \n",
    "        return x_\n",
    "\n",
    "    def unsplit(self, x_, \n",
    "              modes=None\n",
    "              ):\n",
    "        n, b, c, *data_shape = x_.shape\n",
    "        fft_dims = list(range(-len(data_shape), 0))\n",
    "        \n",
    "        Fx_ = torch.fft.fft2(x_, dim=fft_dims, norm='forward') # Fx_ = x_ # \n",
    "        \n",
    "        Fx = torch.zeros((b, c, *data_shape), dtype=Fx_.dtype, device=x_.device)\n",
    "        k = [torch.fft.fftfreq(n, d=1./n) for n in data_shape[:-1]]\n",
    "        k += [torch.fft.rfftfreq(data_shape[-1], d=1./data_shape[-1])] if Fx.dtype in [torch.float16, torch.float32, torch.float64] else [torch.fft.fftfreq(data_shape[-1], d=1./data_shape[-1])]\n",
    "        k = torch.meshgrid(k, indexing='ij')\n",
    "        k = torch.stack(k)\n",
    "        k = torch.sqrt(torch.sum(k**2, axis=0)).to(x_.device)\n",
    "        for i in range(len(modes)):\n",
    "            k1, k2 = modes[i]\n",
    "            idx = (k1 <= k) & (k <= k2)\n",
    "            Fx[..., idx] = Fx_[i, ..., idx]\n",
    "\n",
    "        x = torch.fft.ifft2(Fx, dim=fft_dims, norm='forward').real\n",
    "        return x\n",
    "\n",
    "class FineTunner_1(BaseCallback):\n",
    "    def __init__(self, loss_fn):\n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        self.phase = 1\n",
    "        self.eps = [5e-6, 1e-5]\n",
    "        \n",
    "        self.loss_prev = None\n",
    "\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        pl_module.model.frozen_layer.append('fno')\n",
    "        trainer.train_data_idx = [0]\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        if self.phase == 2 and 'fno' in pl_module.model.frozen_layer:\n",
    "            pl_module.model.frozen_layer.remove('fno')\n",
    "            for param in pl_module.model.lifting.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in pl_module.model.projection.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            pl_module.model.fno_blocks.frozen_layer.append('cnn')\n",
    "            trainer.train_data_idx = [1]\n",
    "            trainer.val_data_idx.remove(0)\n",
    "            trainer.val_data_idx.remove(1)\n",
    "            \n",
    "        if self.phase == 3 and 'cnn' in pl_module.model.fno_blocks.frozen_layer:\n",
    "            pl_module.model.fno_blocks.frozen_layer.remove('cnn')\n",
    "            # for param in pl_module.model.fno_blocks.convs.parameters():\n",
    "            #     param.requires_grad = False\n",
    "            # for param in pl_module.model.fno_blocks.norm.parameters(): \n",
    "            #     param.requires_grad = False\n",
    "\n",
    "    # def forward(self, pl_module.model, loss):\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        loss = outputs\n",
    "        if self.loss_prev is None: \n",
    "            self.loss_prev = loss \n",
    "            return \n",
    "        \n",
    "        res = torch.abs(loss - self.loss_prev).item() \n",
    "        if self.phase == 1 and res <= self.eps[0]:\n",
    "            pl_module.save(path='./checkpoint/FineTunner_Phase1')\n",
    "            print(f'Fine tunning phase {self.phase} Ended. res:', res, 'epoch:', trainer.current_epoch)\n",
    "            self.phase += 1\n",
    "            self.loss_prev = None   \n",
    "            trainer.skip_current_epoch = True\n",
    "        elif self.phase == 2 and res <= self.eps[1]:\n",
    "            pl_module.save(path='./checkpoint/FineTunner_Phase2')\n",
    "            print(f'Fine tunning phase {self.phase} Ended. res:', res, 'epoch:', trainer.current_epoch)\n",
    "            self.phase += 1\n",
    "            self.loss_prev = None\n",
    "            trainer.skip_current_epoch = True\n",
    "        self.loss_prev = loss\n",
    "        wandb.log({'fine_tunner_res': res})\n",
    "\n",
    "class FineTunner(BaseCallback):\n",
    "    def __init__(self, loss_fn):\n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        self.phase = 1\n",
    "        self.eps = [0.3, 1e-3]\n",
    "        \n",
    "        self.loss_prev = None\n",
    "\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        pl_module.model.fno_blocks.frozen_layer.append('cnn')\n",
    "        # trainer.train_data_idx = [1]\n",
    "\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "            \n",
    "        if self.phase == 2 and 'cnn' in pl_module.model.fno_blocks.frozen_layer:\n",
    "            pl_module.model.fno_blocks.frozen_layer.remove('cnn')\n",
    "            for param in pl_module.model.fno_blocks.convs.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in pl_module.model.fno_blocks.norm.parameters(): \n",
    "                param.requires_grad = False\n",
    "            for param in pl_module.model.lifting.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in pl_module.model.projection.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # def forward(self, pl_module.model, loss):\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "        loss = outputs\n",
    "        if self.loss_prev is None: \n",
    "            self.loss_prev = loss \n",
    "            return \n",
    "        \n",
    "        res = loss # torch.abs(loss - self.loss_prev).item() \n",
    "        if self.phase == 1 and res <= self.eps[0]:\n",
    "            pl_module.save(path='./checkpoint/FineTunner_Phase1')\n",
    "            print(f'Fine tunning phase {self.phase} Ended. res:', res, 'epoch:', trainer.current_epoch)\n",
    "            self.phase += 1\n",
    "            self.loss_prev = None   \n",
    "            trainer.skip_current_epoch = True\n",
    "        self.loss_prev = loss\n",
    "        wandb.log({'fine_tunner_res': res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset metadata: dict_keys(['nu', 'Lx', 'Ly', 'dx', 'dy', 'Nx', 'Ny', 'x', 'y', 'dt', 'Nt', 'T', 't0', 't'])\n",
      "{'nu': 0.000225, 'Lx': 1.5402125848364265, 'Ly': 1.5402125848364265, 'dx': 0.024447818806927406, 'dy': 0.024447818806927406, 'Nx': 64, 'Ny': 64, 'x': array([0.        , 0.02444782, 0.04889564, 0.07334346, 0.09779128,\n",
      "       0.12223909, 0.14668691, 0.17113473, 0.19558255, 0.22003037,\n",
      "       0.24447819, 0.26892601, 0.29337383, 0.31782164, 0.34226946,\n",
      "       0.36671728, 0.3911651 , 0.41561292, 0.44006074, 0.46450856,\n",
      "       0.48895638, 0.51340419, 0.53785201, 0.56229983, 0.58674765,\n",
      "       0.61119547, 0.63564329, 0.66009111, 0.68453893, 0.70898675,\n",
      "       0.73343456, 0.75788238, 0.7823302 , 0.80677802, 0.83122584,\n",
      "       0.85567366, 0.88012148, 0.9045693 , 0.92901711, 0.95346493,\n",
      "       0.97791275, 1.00236057, 1.02680839, 1.05125621, 1.07570403,\n",
      "       1.10015185, 1.12459967, 1.14904748, 1.1734953 , 1.19794312,\n",
      "       1.22239094, 1.24683876, 1.27128658, 1.2957344 , 1.32018222,\n",
      "       1.34463003, 1.36907785, 1.39352567, 1.41797349, 1.44242131,\n",
      "       1.46686913, 1.49131695, 1.51576477, 1.54021258]), 'y': array([0.        , 0.02444782, 0.04889564, 0.07334346, 0.09779128,\n",
      "       0.12223909, 0.14668691, 0.17113473, 0.19558255, 0.22003037,\n",
      "       0.24447819, 0.26892601, 0.29337383, 0.31782164, 0.34226946,\n",
      "       0.36671728, 0.3911651 , 0.41561292, 0.44006074, 0.46450856,\n",
      "       0.48895638, 0.51340419, 0.53785201, 0.56229983, 0.58674765,\n",
      "       0.61119547, 0.63564329, 0.66009111, 0.68453893, 0.70898675,\n",
      "       0.73343456, 0.75788238, 0.7823302 , 0.80677802, 0.83122584,\n",
      "       0.85567366, 0.88012148, 0.9045693 , 0.92901711, 0.95346493,\n",
      "       0.97791275, 1.00236057, 1.02680839, 1.05125621, 1.07570403,\n",
      "       1.10015185, 1.12459967, 1.14904748, 1.1734953 , 1.19794312,\n",
      "       1.22239094, 1.24683876, 1.27128658, 1.2957344 , 1.32018222,\n",
      "       1.34463003, 1.36907785, 1.39352567, 1.41797349, 1.44242131,\n",
      "       1.46686913, 1.49131695, 1.51576477, 1.54021258]), 'dt': 0.009999999999999787, 'Nt': 400, 'T': 14.489999999999915, 't0': 10.5, 't': array([10.5 , 10.51, 10.52, 10.53, 10.54, 10.55, 10.56, 10.57, 10.58,\n",
      "       10.59, 10.6 , 10.61, 10.62, 10.63, 10.64, 10.65, 10.66, 10.67,\n",
      "       10.68, 10.69, 10.7 , 10.71, 10.72, 10.73, 10.74, 10.75, 10.76,\n",
      "       10.77, 10.78, 10.79, 10.8 , 10.81, 10.82, 10.83, 10.84, 10.85,\n",
      "       10.86, 10.87, 10.88, 10.89, 10.9 , 10.91, 10.92, 10.93, 10.94,\n",
      "       10.95, 10.96, 10.97, 10.98, 10.99, 11.  , 11.01, 11.02, 11.03,\n",
      "       11.04, 11.05, 11.06, 11.07, 11.08, 11.09, 11.1 , 11.11, 11.12,\n",
      "       11.13, 11.14, 11.15, 11.16, 11.17, 11.18, 11.19, 11.2 , 11.21,\n",
      "       11.22, 11.23, 11.24, 11.25, 11.26, 11.27, 11.28, 11.29, 11.3 ,\n",
      "       11.31, 11.32, 11.33, 11.34, 11.35, 11.36, 11.37, 11.38, 11.39,\n",
      "       11.4 , 11.41, 11.42, 11.43, 11.44, 11.45, 11.46, 11.47, 11.48,\n",
      "       11.49, 11.5 , 11.51, 11.52, 11.53, 11.54, 11.55, 11.56, 11.57,\n",
      "       11.58, 11.59, 11.6 , 11.61, 11.62, 11.63, 11.64, 11.65, 11.66,\n",
      "       11.67, 11.68, 11.69, 11.7 , 11.71, 11.72, 11.73, 11.74, 11.75,\n",
      "       11.76, 11.77, 11.78, 11.79, 11.8 , 11.81, 11.82, 11.83, 11.84,\n",
      "       11.85, 11.86, 11.87, 11.88, 11.89, 11.9 , 11.91, 11.92, 11.93,\n",
      "       11.94, 11.95, 11.96, 11.97, 11.98, 11.99, 12.  , 12.01, 12.02,\n",
      "       12.03, 12.04, 12.05, 12.06, 12.07, 12.08, 12.09, 12.1 , 12.11,\n",
      "       12.12, 12.13, 12.14, 12.15, 12.16, 12.17, 12.18, 12.19, 12.2 ,\n",
      "       12.21, 12.22, 12.23, 12.24, 12.25, 12.26, 12.27, 12.28, 12.29,\n",
      "       12.3 , 12.31, 12.32, 12.33, 12.34, 12.35, 12.36, 12.37, 12.38,\n",
      "       12.39, 12.4 , 12.41, 12.42, 12.43, 12.44, 12.45, 12.46, 12.47,\n",
      "       12.48, 12.49, 12.5 , 12.51, 12.52, 12.53, 12.54, 12.55, 12.56,\n",
      "       12.57, 12.58, 12.59, 12.6 , 12.61, 12.62, 12.63, 12.64, 12.65,\n",
      "       12.66, 12.67, 12.68, 12.69, 12.7 , 12.71, 12.72, 12.73, 12.74,\n",
      "       12.75, 12.76, 12.77, 12.78, 12.79, 12.8 , 12.81, 12.82, 12.83,\n",
      "       12.84, 12.85, 12.86, 12.87, 12.88, 12.89, 12.9 , 12.91, 12.92,\n",
      "       12.93, 12.94, 12.95, 12.96, 12.97, 12.98, 12.99, 13.  , 13.01,\n",
      "       13.02, 13.03, 13.04, 13.05, 13.06, 13.07, 13.08, 13.09, 13.1 ,\n",
      "       13.11, 13.12, 13.13, 13.14, 13.15, 13.16, 13.17, 13.18, 13.19,\n",
      "       13.2 , 13.21, 13.22, 13.23, 13.24, 13.25, 13.26, 13.27, 13.28,\n",
      "       13.29, 13.3 , 13.31, 13.32, 13.33, 13.34, 13.35, 13.36, 13.37,\n",
      "       13.38, 13.39, 13.4 , 13.41, 13.42, 13.43, 13.44, 13.45, 13.46,\n",
      "       13.47, 13.48, 13.49, 13.5 , 13.51, 13.52, 13.53, 13.54, 13.55,\n",
      "       13.56, 13.57, 13.58, 13.59, 13.6 , 13.61, 13.62, 13.63, 13.64,\n",
      "       13.65, 13.66, 13.67, 13.68, 13.69, 13.7 , 13.71, 13.72, 13.73,\n",
      "       13.74, 13.75, 13.76, 13.77, 13.78, 13.79, 13.8 , 13.81, 13.82,\n",
      "       13.83, 13.84, 13.85, 13.86, 13.87, 13.88, 13.89, 13.9 , 13.91,\n",
      "       13.92, 13.93, 13.94, 13.95, 13.96, 13.97, 13.98, 13.99, 14.  ,\n",
      "       14.01, 14.02, 14.03, 14.04, 14.05, 14.06, 14.07, 14.08, 14.09,\n",
      "       14.1 , 14.11, 14.12, 14.13, 14.14, 14.15, 14.16, 14.17, 14.18,\n",
      "       14.19, 14.2 , 14.21, 14.22, 14.23, 14.24, 14.25, 14.26, 14.27,\n",
      "       14.28, 14.29, 14.3 , 14.31, 14.32, 14.33, 14.34, 14.35, 14.36,\n",
      "       14.37, 14.38, 14.39, 14.4 , 14.41, 14.42, 14.43, 14.44, 14.45,\n",
      "       14.46, 14.47, 14.48, 14.49])}\n"
     ]
    }
   ],
   "source": [
    "##### set parameters #####\n",
    "### save parameters ### \n",
    "data_dir = config['data'][0]['params']['base_path'] # '../Data/nu=0.001_n=128/'\n",
    "data_fname = config['data'][0]['params']['dataset_name'] # f'2dHIT_nu=0.001_n=128_T=11.5'\n",
    "\n",
    "metadata = HIT2dDataset(path=data_dir + 'train/' + data_fname, load_data=False).metadata\n",
    "print(metadata)\n",
    "\n",
    "nu = metadata['nu']\n",
    "dt = metadata['dt']\n",
    "N = metadata['Nx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset metadata: dict_keys(['nu', 'Lx', 'Ly', 'dx', 'dy', 'Nx', 'Ny', 'x', 'y', 'dt', 'Nt', 'T', 't0', 't'])\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_0.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_1.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_2.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_3.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_4.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_5.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_6.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_7.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_8.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_9.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded. shape: torch.Size([500, 400, 1, 64, 64]), dtype: torch.float32, time: 1.4285526275634766 (sec), memory: 3276.8 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_0.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_1.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_2.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_3.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_4.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_5.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_6.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_7.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_8.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/train\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_9.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded. shape: torch.Size([500, 400, 1, 64, 64]), dtype: torch.float32, time: 1.4504656791687012 (sec), memory: 3276.8 (MB)\n",
      "Train dataset: 182500\n",
      "Loaded dataset metadata: dict_keys(['nu', 'Lx', 'Ly', 'dx', 'dy', 'Nx', 'Ny', 'x', 'y', 'dt', 'Nt', 'T', 't0', 't'])\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/valid\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_0.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded. shape: torch.Size([50, 400, 1, 64, 64]), dtype: torch.float32, time: 0.1549975872039795 (sec), memory: 327.68 (MB)\n",
      "Data Loaded fromD:\\RESEARCH\\2DIso\\Data\\nu=0.00025_n=256_fDNS=64/valid\\2dHIT_nu=0.000225_n=256_T=14.5_fDNS=64_0.hdf5. shape: (50, 400, 1, 64, 64), memory: 327.68 (MB)\n",
      "Data Loaded. shape: torch.Size([50, 400, 1, 64, 64]), dtype: torch.float32, time: 0.1401042938232422 (sec), memory: 327.68 (MB)\n",
      "Val dataset: 18250\n",
      "Loaded dataset metadata: dict_keys(['nu', 'Lx', 'Ly', 'dx', 'dy', 'Nx', 'Ny', 'x', 'y', 'dt', 'Nt', 'T', 't0', 't'])\n",
      "Val dataset: 365\n"
     ]
    }
   ],
   "source": [
    "from utils.Losses import (RMSLoss, TKELoss, DissipationLoss, RelambdaLoss, R2, \n",
    "                          BSMSE, )\n",
    "from utils.utilities import HsLoss\n",
    "from utils.Losses import BaseLoss\n",
    "\n",
    "class FourierCorrLoss(BaseLoss):\n",
    "    '''\n",
    "    L2 based cos similarity in Fourier space\n",
    "    '''\n",
    "    def __init__(self, \n",
    "        isRelative:bool=False, \n",
    "        norm:Literal['forward', 'ortho', 'backward']='forward', \n",
    "        dim:Union[int, Iterable]=(-2, -1), \n",
    "        *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.isRelative = isRelative\n",
    "        self.dim = dim if isinstance(dim, Iterable) else (dim,)\n",
    "        self.norm = norm\n",
    "    \n",
    "    def forward(self, input:Tensor, target:Tensor) -> Tensor:\n",
    "        F_in = torch.fft.fftn(input, norm=self.norm, dim=self.dim)\n",
    "        F_tar = torch.fft.fftn(target, norm=self.norm, dim=self.dim)\n",
    "\n",
    "        dim = [-(len(self.dim)+1)] + list(self.dim)\n",
    "        Sxy = (F_in * torch.conj(F_tar)).sum(dim=dim)\n",
    "        loss = torch.abs(Sxy)\n",
    "        if self.isRelative: \n",
    "            # norm = torch.sqrt(torch.abs(F_tar).mean(dim=dim)) * torch.sqrt(torch.abs(F_in).mean(dim=dim))\n",
    "            norm = torch.linalg.vector_norm(F_in, dim=dim) * torch.linalg.vector_norm(F_tar, dim=dim)\n",
    "            loss = loss / (norm + 1e-8)\n",
    "            loss = - torch.log(loss) # loss = 1.0 - loss\n",
    "\n",
    "        if self.reduction == 'mean': loss = loss.mean()\n",
    "        elif self.reduction =='sum': loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class FourierWeightedMSELoss(BaseLoss):\n",
    "    '''\n",
    "    L2 based cos similarity in Fourier space\n",
    "    '''\n",
    "    def __init__(self, \n",
    "        # norm:Literal['forward', 'ortho', 'backward']='ortho', \n",
    "        dim:Union[int, Iterable]=(-2, -1), \n",
    "        *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dim = dim if isinstance(dim, Iterable) else (dim,)\n",
    "        self.norm = 'ortho'\n",
    "    \n",
    "    def forward(self, input:Tensor, target:Tensor) -> Tensor:\n",
    "        err = input - target\n",
    "        Ferr = torch.fft.fftn(err, norm=self.norm, dim=self.dim)\n",
    "        # F_in = torch.fft.fftn(input, norm=self.norm, dim=self.dim)\n",
    "        F_tar = torch.fft.fftn(target, norm=self.norm, dim=self.dim)\n",
    "\n",
    "        loss = torch.abs(Ferr)**2\n",
    "        weight = torch.exp(loss / (torch.abs(F_tar)**2 + 1e-8))\n",
    "        weight = (weight ) / weight.mean()\n",
    "        loss = loss * weight\n",
    "        \n",
    "\n",
    "        dim = [-(len(self.dim)+1)] + list(self.dim)\n",
    "        loss = loss.mean(dim=dim)\n",
    "\n",
    "        if self.reduction == 'mean': loss = loss.mean()\n",
    "        elif self.reduction =='sum': loss = loss.sum()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "class CustomLoss(BaseLoss):\n",
    "    def __init__(self, \n",
    "        isRelative:bool=False, \n",
    "        norm:Literal['forward', 'ortho', 'backward']='forward', \n",
    "        dim:Union[int, Iterable]=(-2, -1), \n",
    "        *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss1 = FourierCorrLoss(isRelative=isRelative, norm=norm, dim=dim)\n",
    "        self.loss2 = nn.MSELoss() # FourierWeightedMSELoss(*args, **kwargs) # nn.MSELoss()\n",
    "    \n",
    "    def forward(self, input:Tensor, target:Tensor) -> Tensor:\n",
    "        # loss1 = self.loss1(input, target)\n",
    "        loss2 = self.loss2(input, target)\n",
    "        loss = loss2#  + loss2\n",
    "        return loss\n",
    "\n",
    "test_criterion={\n",
    "    'l2': nn.MSELoss(), \n",
    "    'h1': H1Loss(d=2, reduction='mean'), \n",
    "    'h2': HsLoss(k=2, reduction='mean'), # HsLoss(k=2, group=False, size_average=True), \n",
    "    'fftcorr': FourierCorrLoss(reduction='mean', isRelative=True,dim=(-2, -1), norm='backward'),\n",
    "    \n",
    "    'fRMS_k<8': BSMSE(kmax=8, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_8<k<16': BSMSE(kmin=8, kmax=16, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_k>16': BSMSE(kmin=16, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_k<kmax': BSMSE(kmax=16, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_k>kmax': BSMSE(kmin=16, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_k>train': BSMSE(kmin=32, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "    'fRMS_k<train': BSMSE(kmax=32, dim=(-2, -1), mode='spectral', isRelative=True),\n",
    "\n",
    "    'vor_rms': RMSLoss(dim=2, isRelative=True),\n",
    "    # 'tke': TKELoss(dim=2, isRelative=True), \n",
    "    # 'dissipation': DissipationLoss(nu=nu, dim=2, isRelative=True), \n",
    "    # 'R_lambda': RelambdaLoss(nu=nu, dim=2, isRelative=True), \n",
    "    'R_squared': R2(), \n",
    "    }\n",
    "\n",
    "##### setup dataset #####\n",
    "dataloaders = {'train':[], 'valid': [], 'test': []}\n",
    "for i, data_config in enumerate(config['data']):\n",
    "    transform = CustomTransform()\n",
    "    normalization = Standardize(normalization_path=data_config['normalization']['normalization_path'])\n",
    "\n",
    "    idx_leadtime = data_config['idx_leadtime'] if 'idx_leadtime' in data_config else int(data_config['leadtime'] * integral_timescales[nu] / dt) \n",
    "    # load_data = data_config['stage'] in ['fit', 'train']\n",
    "    dm = CustomDataModule(**data_config['params'], \n",
    "        n_stride=idx_leadtime, \n",
    "        # Ndata_train=500, # 500, \n",
    "        # Ndata_val=50, \n",
    "        # Ndata_test=50,\n",
    "        # transform=transform,\n",
    "        normalization=normalization,\n",
    "        # load_data=load_data,\n",
    "        )\n",
    "    stage = data_config['stage']\n",
    "    dm.setup(stage=stage)\n",
    "    if stage in ['fit', 'valid']:\n",
    "        dataloaders['valid'].append(dm.val_dataloader())\n",
    "    if stage in ['fit', 'train']:\n",
    "        dataloaders['train'].append(dm.train_dataloader())\n",
    "    if stage in ['test']:\n",
    "        dataloaders['test'].append(dm.test_dataloader())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "======================================================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
      "======================================================================================================================================================\n",
      "FNO                                                [64, 1, 64, 64]           [64, 1, 64, 64]           --                        Partial\n",
      "├─ChannelMLP: 1-1                                  [64, 1, 64, 64]           [64, 64, 64, 64]          8,256                     True\n",
      "│    └─ModuleList: 2-3                             --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-1                            [64, 1, 4096]             [64, 128, 4096]           256                       True\n",
      "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
      "│    └─GELU: 2-2                                   [64, 128, 4096]           [64, 128, 4096]           --                        --\n",
      "├─ChannelMLP: 1-3                                  --                        --                        (recursive)               True\n",
      "│    └─ModuleList: 2-3                             --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-2                            [64, 128, 4096]           [64, 64, 4096]            8,256                     True\n",
      "├─FNOBlocks: 1-4                                   [64, 64, 64, 64]          [64, 64, 64, 64]          6,817,984                 Partial\n",
      "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
      "│    │    └─SpectralConv: 3-3                      [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
      "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
      "│    │    └─InstanceNorm: 3-4                      [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
      "│    │    └─Sequential: 3-5                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
      "│    │    │    └─WTConv2d: 4-1                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-3              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-4              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-3              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-4              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-5                  [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-6            [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-2               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-3                         [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─WTConv2d: 4-4                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-9              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-10             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-9              --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-10             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-11                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-12           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-5               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-6                         [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
      "│    └─GELU: 2-7                                   [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
      "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
      "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
      "│    │    └─Sequential: 3-6                        [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-7                       [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
      "├─FNOBlocks: 1-7                                   [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
      "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
      "│    │    └─SpectralConv: 3-7                      [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
      "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
      "│    │    └─InstanceNorm: 3-8                      [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
      "│    │    └─Sequential: 3-9                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
      "│    │    │    └─WTConv2d: 4-8                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-15             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-16             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-15             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-16             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-17                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-18           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-9               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-10                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─WTConv2d: 4-11                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-21             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-22             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-21             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-22             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-23                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-24           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-12              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-13                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
      "│    └─GELU: 2-12                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
      "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
      "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
      "│    │    └─Sequential: 3-10                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-14                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
      "├─FNOBlocks: 1-10                                  [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
      "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
      "│    │    └─SpectralConv: 3-11                     [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
      "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
      "│    │    └─InstanceNorm: 3-12                     [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
      "│    │    └─Sequential: 3-13                       [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
      "│    │    │    └─WTConv2d: 4-15                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-27             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-28             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-27             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-28             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-29                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-30           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-16              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-17                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─WTConv2d: 4-18                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-33             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-34             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-33             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-34             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-35                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-36           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-19              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-20                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
      "│    └─GELU: 2-17                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
      "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
      "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
      "│    │    └─Sequential: 3-14                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-21                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
      "├─FNOBlocks: 1-13                                  [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
      "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
      "│    │    └─SpectralConv: 3-15                     [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
      "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
      "│    │    └─InstanceNorm: 3-16                     [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
      "│    │    └─Sequential: 3-17                       [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
      "│    │    │    └─WTConv2d: 4-22                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-39             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-40             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-39             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-40             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-41                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-42           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-23              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-24                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─WTConv2d: 4-25                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
      "│    │    │    │    └─ModuleList: 5-45             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-46             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-45             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─ModuleList: 5-46             --                        --                        (recursive)               True\n",
      "│    │    │    │    └─Conv2d: 5-47                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
      "│    │    │    │    └─_ScaleModule: 5-48           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
      "│    │    │    └─InstanceNorm2d: 4-26              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "│    │    │    └─GELU: 4-27                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
      "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
      "│    └─GELU: 2-22                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
      "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
      "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
      "│    │    └─Sequential: 3-18                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
      "│    │    │    └─Conv2d: 4-28                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
      "├─ChannelMLP: 1-16                                 [64, 64, 64, 64]          [64, 1, 64, 64]           --                        True\n",
      "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-19                           [64, 64, 4096]            [64, 512, 4096]           33,280                    True\n",
      "│    └─GELU: 2-25                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
      "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-20                           [64, 512, 4096]           [64, 512, 4096]           262,656                   True\n",
      "│    └─GELU: 2-27                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
      "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-21                           [64, 512, 4096]           [64, 512, 4096]           262,656                   True\n",
      "│    └─GELU: 2-29                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
      "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
      "│    │    └─Conv1d: 3-22                           [64, 512, 4096]           [64, 1, 4096]             513                       True\n",
      "======================================================================================================================================================\n",
      "Total params: 16,451,649\n",
      "Trainable params: 16,336,961\n",
      "Non-trainable params: 114,688\n",
      "Total mult-adds (G): 160.17\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 8994.68\n",
      "Params size (MB): 2.59\n",
      "Estimated Total Size (MB): 8998.32\n",
      "======================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
       "======================================================================================================================================================\n",
       "FNO                                                [64, 1, 64, 64]           [64, 1, 64, 64]           --                        Partial\n",
       "├─ChannelMLP: 1-1                                  [64, 1, 64, 64]           [64, 64, 64, 64]          8,256                     True\n",
       "│    └─ModuleList: 2-3                             --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-1                            [64, 1, 4096]             [64, 128, 4096]           256                       True\n",
       "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
       "│    └─GELU: 2-2                                   [64, 128, 4096]           [64, 128, 4096]           --                        --\n",
       "├─ChannelMLP: 1-3                                  --                        --                        (recursive)               True\n",
       "│    └─ModuleList: 2-3                             --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-2                            [64, 128, 4096]           [64, 64, 4096]            8,256                     True\n",
       "├─FNOBlocks: 1-4                                   [64, 64, 64, 64]          [64, 64, 64, 64]          6,817,984                 Partial\n",
       "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
       "│    │    └─SpectralConv: 3-3                      [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
       "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
       "│    │    └─InstanceNorm: 3-4                      [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
       "│    │    └─Sequential: 3-5                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
       "│    │    │    └─WTConv2d: 4-1                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-3              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-4              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-3              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-4              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-5                  [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-6            [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-2               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-3                         [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─WTConv2d: 4-4                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-9              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-10             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-9              --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-10             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-11                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-12           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-5               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-6                         [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
       "│    └─GELU: 2-7                                   [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
       "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
       "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
       "│    │    └─Sequential: 3-6                        [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
       "│    │    │    └─Conv2d: 4-7                       [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
       "├─FNOBlocks: 1-7                                   [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
       "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
       "│    │    └─SpectralConv: 3-7                      [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
       "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
       "│    │    └─InstanceNorm: 3-8                      [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
       "│    │    └─Sequential: 3-9                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
       "│    │    │    └─WTConv2d: 4-8                     [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-15             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-16             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-15             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-16             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-17                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-18           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-9               [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-10                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─WTConv2d: 4-11                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-21             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-22             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-21             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-22             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-23                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-24           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-12              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-13                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
       "│    └─GELU: 2-12                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
       "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
       "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
       "│    │    └─Sequential: 3-10                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
       "│    │    │    └─Conv2d: 4-14                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
       "├─FNOBlocks: 1-10                                  [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
       "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
       "│    │    └─SpectralConv: 3-11                     [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
       "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
       "│    │    └─InstanceNorm: 3-12                     [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
       "│    │    └─Sequential: 3-13                       [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
       "│    │    │    └─WTConv2d: 4-15                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-27             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-28             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-27             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-28             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-29                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-30           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-16              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-17                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─WTConv2d: 4-18                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-33             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-34             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-33             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-34             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-35                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-36           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-19              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-20                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
       "│    └─GELU: 2-17                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
       "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
       "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
       "│    │    └─Sequential: 3-14                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
       "│    │    │    └─Conv2d: 4-21                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
       "├─FNOBlocks: 1-13                                  [64, 64, 64, 64]          [64, 64, 64, 64]          (recursive)               Partial\n",
       "│    └─ModuleList: 2-19                            --                        --                        (recursive)               True\n",
       "│    │    └─SpectralConv: 3-15                     [64, 64, 64, 64]          [64, 64, 64, 64]          2,228,288                 True\n",
       "│    └─ModuleList: 2-20                            --                        --                        --                        --\n",
       "│    │    └─InstanceNorm: 3-16                     [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    └─ModuleList: 2-21                            --                        --                        (recursive)               Partial\n",
       "│    │    └─Sequential: 3-17                       [64, 64, 64, 64]          [64, 64, 64, 64]          --                        Partial\n",
       "│    │    │    └─WTConv2d: 4-22                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-39             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-40             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-39             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-40             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-41                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-42           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-23              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-24                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─WTConv2d: 4-25                    [64, 64, 64, 64]          [64, 64, 64, 64]          8,192                     Partial\n",
       "│    │    │    │    └─ModuleList: 5-45             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-46             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-45             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─ModuleList: 5-46             --                        --                        (recursive)               True\n",
       "│    │    │    │    └─Conv2d: 5-47                 [64, 64, 64, 64]          [64, 64, 64, 64]          576                       True\n",
       "│    │    │    │    └─_ScaleModule: 5-48           [64, 64, 64, 64]          [64, 64, 64, 64]          64                        True\n",
       "│    │    │    └─InstanceNorm2d: 4-26              [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "│    │    │    └─GELU: 4-27                        [64, 64, 64, 64]          [64, 64, 64, 64]          --                        --\n",
       "├─ChannelMLP: 1-14                                 --                        --                        (recursive)               True\n",
       "│    └─GELU: 2-22                                  [64, 128, 64, 64]         [64, 128, 64, 64]         --                        --\n",
       "├─FNOBlocks: 1-15                                  --                        --                        (recursive)               Partial\n",
       "│    └─ModuleList: 2-23                            --                        --                        (recursive)               True\n",
       "│    │    └─Sequential: 3-18                       [64, 128, 64, 64]         [64, 64, 64, 64]          --                        True\n",
       "│    │    │    └─Conv2d: 4-28                      [64, 128, 64, 64]         [64, 64, 64, 64]          8,256                     True\n",
       "├─ChannelMLP: 1-16                                 [64, 64, 64, 64]          [64, 1, 64, 64]           --                        True\n",
       "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-19                           [64, 64, 4096]            [64, 512, 4096]           33,280                    True\n",
       "│    └─GELU: 2-25                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
       "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-20                           [64, 512, 4096]           [64, 512, 4096]           262,656                   True\n",
       "│    └─GELU: 2-27                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
       "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-21                           [64, 512, 4096]           [64, 512, 4096]           262,656                   True\n",
       "│    └─GELU: 2-29                                  [64, 512, 4096]           [64, 512, 4096]           --                        --\n",
       "│    └─ModuleList: 2-30                            --                        --                        (recursive)               True\n",
       "│    │    └─Conv1d: 3-22                           [64, 512, 4096]           [64, 1, 4096]             513                       True\n",
       "======================================================================================================================================================\n",
       "Total params: 16,451,649\n",
       "Trainable params: 16,336,961\n",
       "Non-trainable params: 114,688\n",
       "Total mult-adds (G): 160.17\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 1.05\n",
       "Forward/backward pass size (MB): 8994.68\n",
       "Params size (MB): 2.59\n",
       "Estimated Total Size (MB): 8998.32\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from utils.neuraloperator import FNO\n",
    "from torchinfo import summary\n",
    "\n",
    "model = FNO(**config['model']['params'])\n",
    "pl_module = CustomModule(\n",
    "        model=model, \n",
    "        optconfig=config['optimizer'], \n",
    "        )\n",
    "batch_size = config['data'][0]['params']['batch_size']\n",
    "print(pl_module.device)\n",
    "summary(\n",
    "        pl_module.model,\n",
    "        input_size=(batch_size, 1, N, N),       # batch_size, in_channels, H, W\n",
    "        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
    "        depth=5,                           # how many nested modules to show\n",
    "        verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Trainer import Trainer\n",
    "from utils.DLCallbacks import CheckPoint, EarlyStopping\n",
    "from utils.CFDCallback_Spectrum import CFDCallback_Spectrum\n",
    "from utils.CFDCallback_PhaseError import CFDCallback_PhaseError\n",
    "from utils.CFDCallback_PDF import CFDCallback_PDF\n",
    "from utils.CFDCallback_Field import CFDCallback_Field\n",
    "\n",
    "def main(device='cuda'):\n",
    "    logger = None \n",
    "    logger = wandb.init(project=config['name'], \n",
    "                        # name=config['name'], \n",
    "                        config=config\n",
    "                        )\n",
    "    if 'seed' in config: torch.manual_seed(config['seed'])\n",
    "\n",
    "    data_config = config['data'][0]\n",
    "    fname=f\"2dHIT_{config['model']['name']}_nu={data_config['nu']}\"\n",
    "    fname += f\"_T={data_config['idx_leadtime']}\" if 'idx_leadtime' in data_config else f\"_T={data_config['leadtime']}TL\"\n",
    "    if logger: fname += f'_{logger.name}'\n",
    "\n",
    "    optconfig = config['optimizer']\n",
    "    if 'loss_fn' in config: optconfig['loss_fn'] = config['loss_fn']\n",
    "    if 'lr' in config: optconfig['params']['lr'] = config['lr']\n",
    "    modelconfig = {**config['model'], }\n",
    "    modelconfig['params'].update({k: v for k, v in config.items() if k in config['model']['params']})\n",
    "    \n",
    "    model = FNO(**config['model']['params'])\n",
    "    pl_module = CustomModule(\n",
    "            model=model, \n",
    "            optconfig=config['optimizer'], \n",
    "            loss_fn=CustomLoss(reduction='mean', isRelative=True,dim=(-2, -1), norm='backward'), # test_criterion['h1'],\n",
    "            fine_tunner = FineTunner,\n",
    "            )\n",
    "    # pl_module.load('./pretrain/2dHIT_FNO_nu=5e-05_T=0.1TL_different-dust-234_top0', \n",
    "    #     # load_opt=False, \n",
    "    #     # freeze=True, \n",
    "    #     )\n",
    "    if logger: wandb.watch(pl_module, log=\"all\", log_freq=100)\n",
    "    callbacks = [\n",
    "            # FineTunner(loss_fn=test_criterion['h1']),\n",
    "            CFDCallback_Spectrum(file_dir='./result/', fname=fname), \n",
    "            CFDCallback_PhaseError(file_dir='./result/', fname=fname), \n",
    "            CFDCallback_PDF(file_dir='./result/', fname=fname), \n",
    "            CFDCallback_Field(file_dir='./result/', fname=fname), \n",
    "            CustomCallback(criterions=test_criterion, file_dir='./result/', fname=fname, device=device,\n",
    "                        ),\n",
    "            CheckPoint(\n",
    "                ckpt_name=fname, ckpt_path='./checkpoint/', \n",
    "                every_n_epoch = 1,\n",
    "                criterion=nn.MSELoss(), mode = 'min', \n",
    "                load_ckpt=False, \n",
    "                ),\n",
    "            EarlyStopping(criterion=nn.MSELoss(), # neuralop.H1Loss(d=2, reductions='mean'),# \n",
    "                            mode='min', min_delta=1e-5, \n",
    "                            patience=5, verbose=True, divergence_threshold=1e3, \n",
    "                            stopping_threshold=1e-3, \n",
    "                            ),\n",
    "            ]\n",
    "    trainer = Trainer(\n",
    "        max_epochs=config['epochs'],\n",
    "        check_val_every_n_epochs=1,\n",
    "        # check_val_every_n_iter=30000, \n",
    "        enable_progress_bar=True,\n",
    "        callbacks=callbacks, \n",
    "        logger=logger,\n",
    "        )\n",
    "    \n",
    "    trainer.fit(\n",
    "        model=pl_module,\n",
    "        train_dataloaders=dataloaders['train'], \n",
    "        val_dataloaders=dataloaders['valid'],\n",
    "        # datamodule = datamodules,\n",
    "        )\n",
    "    if logger: wandb.finish()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: hjungwon034 (jungwonheo) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\RESEARCH\\2DIso\\DL_ours_FNOKernel\\wandb\\run-20251113_202018-ulg88sek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all/runs/ulg88sek' target=\"_blank\">smooth-fog-22</a></strong> to <a href='https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all' target=\"_blank\">https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all/runs/ulg88sek' target=\"_blank\">https://wandb.ai/jungwonheo/2dHIT_FNOKernel_all/runs/ulg88sek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 99/2851 [00:34<12:15,  3.74it/s] c:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\wandb\\integration\\torch\\wandb_torch.py:197: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:250.)\n",
      "  flat = flat.type(torch.cuda.FloatTensor)\n",
      "100%|██████████| 2851/2851 [13:32<00:00,  3.51it/s]  \n",
      "c:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 285/285 [00:52<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 0, l2: 0.026258, h1: 0.261230, h2: 0.547523, fftcorr: 0.013221, fRMS_k<8: 0.003981, fRMS_8<k<16: 0.024596, fRMS_k>16: 0.156438, fRMS_k<kmax: 0.007430, fRMS_k>kmax: 0.156438, fRMS_k>train: 0.729609, fRMS_k<train: 0.021932, vor_rms: 0.014225, R_squared: 0.973705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:54<00:00, 22.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 0, l2: 0.192807, h1: 1.032330, h2: 1.832671, fftcorr: 0.102136, fRMS_k<8: 0.007103, fRMS_8<k<16: 0.077646, fRMS_k>16: 1.040778, fRMS_k<kmax: 0.020304, fRMS_k>kmax: 1.040778, fRMS_k>train: 1.414054, fRMS_k<train: 0.112965, vor_rms: 0.079555, R_squared: 0.814938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:29<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:52<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 1, l2: 0.020229, h1: 0.228249, h2: 0.493181, fftcorr: 0.010068, fRMS_k<8: 0.002898, fRMS_8<k<16: 0.019450, fRMS_k>16: 0.118260, fRMS_k<kmax: 0.005668, fRMS_k>kmax: 0.118260, fRMS_k>train: 0.608422, fRMS_k<train: 0.016618, vor_rms: 0.011402, R_squared: 0.979736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:52<00:00, 22.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 1, l2: 0.185233, h1: 1.009910, h2: 1.653715, fftcorr: 0.097495, fRMS_k<8: 0.006415, fRMS_8<k<16: 0.069130, fRMS_k>16: 1.006801, fRMS_k<kmax: 0.018139, fRMS_k>kmax: 1.006801, fRMS_k>train: 1.349780, fRMS_k<train: 0.109047, vor_rms: 0.067257, R_squared: 0.822217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:30<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:53<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 2, l2: 0.018191, h1: 0.214784, h2: 0.469521, fftcorr: 0.009129, fRMS_k<8: 0.002728, fRMS_8<k<16: 0.017855, fRMS_k>16: 0.104136, fRMS_k<kmax: 0.005261, fRMS_k>kmax: 0.104136, fRMS_k>train: 0.536058, fRMS_k<train: 0.014870, vor_rms: 0.010857, R_squared: 0.981790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:56<00:00, 23.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 2, l2: 0.183068, h1: 1.000263, h2: 1.581211, fftcorr: 0.096459, fRMS_k<8: 0.006094, fRMS_8<k<16: 0.071020, fRMS_k>16: 0.993505, fRMS_k<kmax: 0.018242, fRMS_k>kmax: 0.993505, fRMS_k>train: 1.318405, fRMS_k<train: 0.108681, vor_rms: 0.075870, R_squared: 0.824325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:31<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:51<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 3, l2: 0.017245, h1: 0.209673, h2: 0.458175, fftcorr: 0.008656, fRMS_k<8: 0.002450, fRMS_8<k<16: 0.017641, fRMS_k>16: 0.098409, fRMS_k<kmax: 0.004993, fRMS_k>kmax: 0.098409, fRMS_k>train: 0.499724, fRMS_k<train: 0.014064, vor_rms: 0.011298, R_squared: 0.982743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:03<00:00, 24.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 3, l2: 0.183240, h1: 0.997674, h2: 1.568324, fftcorr: 0.096719, fRMS_k<8: 0.005792, fRMS_8<k<16: 0.075118, fRMS_k>16: 0.991840, fRMS_k<kmax: 0.018760, fRMS_k>kmax: 0.991840, fRMS_k>train: 1.310132, fRMS_k<train: 0.109344, vor_rms: 0.087561, R_squared: 0.824152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:29<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:52<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 4, l2: 0.016878, h1: 0.207385, h2: 0.451577, fftcorr: 0.008451, fRMS_k<8: 0.002419, fRMS_8<k<16: 0.017802, fRMS_k>16: 0.095426, fRMS_k<kmax: 0.004997, fRMS_k>kmax: 0.095426, fRMS_k>train: 0.502753, fRMS_k<train: 0.013778, vor_rms: 0.008464, R_squared: 0.983104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:07<00:00, 25.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 4, l2: 0.183764, h1: 1.000166, h2: 1.571732, fftcorr: 0.096956, fRMS_k<8: 0.005763, fRMS_8<k<16: 0.075262, fRMS_k>16: 0.995134, fRMS_k<kmax: 0.018772, fRMS_k>kmax: 0.995134, fRMS_k>train: 1.317000, fRMS_k<train: 0.109508, vor_rms: 0.079906, R_squared: 0.823615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:30<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:51<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 5, l2: 0.016602, h1: 0.206207, h2: 0.447674, fftcorr: 0.008318, fRMS_k<8: 0.002295, fRMS_8<k<16: 0.018000, fRMS_k>16: 0.093875, fRMS_k<kmax: 0.004924, fRMS_k>kmax: 0.093875, fRMS_k>train: 0.504001, fRMS_k<train: 0.013556, vor_rms: 0.007960, R_squared: 0.983380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:12<00:00, 26.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 5, l2: 0.184074, h1: 1.001701, h2: 1.562377, fftcorr: 0.097181, fRMS_k<8: 0.005791, fRMS_8<k<16: 0.075981, fRMS_k>16: 0.996307, fRMS_k<kmax: 0.018915, fRMS_k>kmax: 0.996307, fRMS_k>train: 1.321894, fRMS_k<train: 0.109552, vor_rms: 0.082652, R_squared: 0.823300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:31<00:00,  3.51it/s]  \n",
      "100%|██████████| 285/285 [00:52<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 6, l2: 0.016415, h1: 0.204940, h2: 0.444890, fftcorr: 0.008244, fRMS_k<8: 0.002241, fRMS_8<k<16: 0.018113, fRMS_k>16: 0.092459, fRMS_k<kmax: 0.004900, fRMS_k>kmax: 0.092459, fRMS_k>train: 0.489713, fRMS_k<train: 0.013402, vor_rms: 0.009206, R_squared: 0.983571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:10<00:00, 26.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 6, l2: 0.184099, h1: 0.999897, h2: 1.544624, fftcorr: 0.097238, fRMS_k<8: 0.005845, fRMS_8<k<16: 0.077434, fRMS_k>16: 0.994899, fRMS_k<kmax: 0.019240, fRMS_k>kmax: 0.994899, fRMS_k>train: 1.317191, fRMS_k<train: 0.109870, vor_rms: 0.086371, R_squared: 0.823267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:31<00:00,  3.51it/s]  \n",
      "100%|██████████| 285/285 [00:52<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 7, l2: 0.016451, h1: 0.205321, h2: 0.443490, fftcorr: 0.008263, fRMS_k<8: 0.002253, fRMS_8<k<16: 0.018597, fRMS_k>16: 0.092267, fRMS_k<kmax: 0.004991, fRMS_k>kmax: 0.092267, fRMS_k>train: 0.495683, fRMS_k<train: 0.013459, vor_rms: 0.008414, R_squared: 0.983533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:06<00:00, 25.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 7, l2: 0.184615, h1: 1.000971, h2: 1.549243, fftcorr: 0.097539, fRMS_k<8: 0.005988, fRMS_8<k<16: 0.078870, fRMS_k>16: 0.996021, fRMS_k<kmax: 0.019625, fRMS_k>kmax: 0.996021, fRMS_k>train: 1.320612, fRMS_k<train: 0.110202, vor_rms: 0.086112, R_squared: 0.822767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2851/2851 [13:29<00:00,  3.52it/s]  \n",
      "100%|██████████| 285/285 [00:52<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 8, l2: 0.016439, h1: 0.205515, h2: 0.442982, fftcorr: 0.008251, fRMS_k<8: 0.002221, fRMS_8<k<16: 0.018812, fRMS_k>16: 0.092216, fRMS_k<kmax: 0.004999, fRMS_k>kmax: 0.092216, fRMS_k>train: 0.499853, fRMS_k<train: 0.013458, vor_rms: 0.007664, R_squared: 0.983544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:18<00:00, 27.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Epoch: 8, l2: 0.184645, h1: 1.002216, h2: 1.550311, fftcorr: 0.097547, fRMS_k<8: 0.005890, fRMS_8<k<16: 0.078510, fRMS_k>16: 0.997069, fRMS_k<kmax: 0.019476, fRMS_k>kmax: 0.997069, fRMS_k>train: 1.324199, fRMS_k<train: 0.110035, vor_rms: 0.084199, R_squared: 0.822721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1636/2851 [07:53<05:52,  3.45it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 68\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m     39\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# FineTunner(loss_fn=test_criterion['h1']),\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         CFDCallback_Spectrum(file_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./result/\u001b[39m\u001b[38;5;124m'\u001b[39m, fname\u001b[38;5;241m=\u001b[39mfname), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m                         ),\n\u001b[0;32m     58\u001b[0m         ]\n\u001b[0;32m     59\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     60\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     61\u001b[0m     check_val_every_n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m     66\u001b[0m     )\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# datamodule = datamodules,\u001b[39;49;00m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32md:\\RESEARCH\\2DIso\\DL_ours_FNOKernel\\utils\\Trainer.py:92\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m     90\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m train_dataloaders[i]\n\u001b[0;32m     91\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m## validation \u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_dataloaders \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_val_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32md:\\RESEARCH\\2DIso\\DL_ours_FNOKernel\\utils\\Trainer.py:120\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, model, dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar_wrapper(\u001b[38;5;28menumerate\u001b[39m(dataloaders), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders)):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, pl_module\u001b[38;5;241m=\u001b[39mmodel, batch\u001b[38;5;241m=\u001b[39mbatch, batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx) \n\u001b[1;32m--> 120\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mfloat\u001b[39m): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_loss\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks\u001b[38;5;241m.\u001b[39mcall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, pl_module\u001b[38;5;241m=\u001b[39mmodel, outputs\u001b[38;5;241m=\u001b[39moutputs, batch\u001b[38;5;241m=\u001b[39mbatch, batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx)\n",
      "Cell \u001b[1;32mIn[8], line 131\u001b[0m, in \u001b[0;36mCustomModule.training_step\u001b[1;34m(self, batch, batch_idx, ret_log)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m hook\u001b[38;5;241m.\u001b[39mhook_every_n_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: hook\u001b[38;5;241m.\u001b[39mopen_hook()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 131\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(output, target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    133\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[8], line 121\u001b[0m, in \u001b[0;36mCustomModule.forward\u001b[1;34m(self, data, output_shape)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 780\u001b[0m, in \u001b[0;36mFNO.forward\u001b[1;34m(self, x, output_shape, *args, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook: hook\u001b[38;5;241m.\u001b[39mset_prefix(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFNO Layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 780\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfno_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# positional_encoder=self.positional_encoder\u001b[39;49;00m\n\u001b[0;32m    782\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# x *= pe.to(x.device)\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook: hook\u001b[38;5;241m.\u001b[39mset_prefix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 664\u001b[0m, in \u001b[0;36mFNOBlocks.forward\u001b[1;34m(self, x, index, output_shape, positional_encoder)\u001b[0m\n\u001b[0;32m    659\u001b[0m x_cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_skip[index](x)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;66;03m# if hook: hook(x_cnn, 'cnn(hpf(x))')\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;66;03m# x_cnn = self.low_pass_filter(x_cnn)\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;66;03m# if hook: hook(x_cnn, 'hpf(cnn(hpf(x)))')\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook: \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_cnn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;66;03m# x = x_fno + x_cnn\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# x_cnn = x * x_cnn\u001b[39;00m\n\u001b[0;32m    667\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([x_fno, x_cnn], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# x = x_fno\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JungwonHeo\\anaconda3\\envs\\FNOv1\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m, in \u001b[0;36mHook.__call__\u001b[1;34m(self, x, name, model)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix: \n\u001b[0;32m     49\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrum\u001b[39m\u001b[38;5;124m'\u001b[39m][name] \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNOv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
